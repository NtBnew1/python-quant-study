'''
ç¬¬13å¤©ï¼š
æ•´åˆæŠ•èµ„ç»„åˆä¼˜åŒ–ã€é£é™©åˆ†æä¸å›æµ‹æ¨¡å—ã€‚
ç»ƒä¹ ï¼šè¾“å‡ºå®Œæ•´æŠ•èµ„ç»„åˆåˆ†ææŠ¥å‘Šï¼ˆåŒ…å«å›¾è¡¨å’Œå…³é”®æŒ‡æ ‡ï¼‰ã€‚
'''

# å¯¼å…¥åº“
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings
import os
from scipy.optimize import minimize


warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False

class CompletePortfolioAnalyzer:
    """
       å®Œæ•´çš„æŠ•èµ„ç»„åˆåˆ†æç³»ç»Ÿ
       åŒ…å«ï¼šä¼˜åŒ– + é£é™©åˆ†æ + å›æµ‹ + æŠ¥å‘Š + å›¾è¡¨
       """
    def __init__(self, stock_returns, risk_free_rate=0.03):
        """
                åˆå§‹åŒ–åˆ†æå™¨

                å‚æ•°:
                stock_returns: è‚¡ç¥¨æ”¶ç›Šç‡DataFrame (æ—¥æœŸä¸ºç´¢å¼•ï¼Œè‚¡ç¥¨ä¸ºåˆ—)
                risk_free_rate: æ— é£é™©åˆ©ç‡ (å¹´åŒ–)
                """
        # 1. å­˜å‚¨è¾“å…¥æ•°æ®
        self.stock_returns = stock_returns      # å­˜å‚¨è‚¡ç¥¨æ”¶ç›Šç‡æ•°æ®
        # 2. è½¬æ¢æ— é£é™©åˆ©ç‡ï¼ˆå¹´åŒ–â†’æ—¥åˆ©ç‡ï¼Œå‡è®¾252ä¸ªäº¤æ˜“æ—¥ï¼‰
        self.risk_free_rate = risk_free_rate / 252      # è½¬æ¢ä¸ºæ—¥åˆ©ç‡
        # 3. è®¡ç®—è‚¡ç¥¨æ•°é‡ï¼ˆåˆ—æ•°ï¼‰
        self.n_stocks = len(stock_returns.columns)
        # 4. è·å–è‚¡ç¥¨åç§°åˆ—è¡¨
        self.stock_names = stock_returns.columns.tolist()

        # 5. åˆå§‹åŒ–å­˜å‚¨ä¼˜åŒ–ç»“æœçš„å˜é‡
        self.max_sharpe_result = None       # å­˜å‚¨æœ€å¤§åŒ–å¤æ™®æ¯”ç‡çš„ç»“æœ
        self.min_vol_result = None          # å­˜å‚¨æœ€å°åŒ–æ³¢åŠ¨ç‡çš„ç»“æœ
        self.efficient_frontier = None      # å­˜å‚¨æœ‰æ•ˆå‰æ²¿æ•°æ®

        # 6. è®¡ç®—åŸºç¡€ç»Ÿè®¡æŒ‡æ ‡ï¼ˆè°ƒç”¨ç§æœ‰æ–¹æ³•ï¼‰
        self._calculate_basic_stats()

        # 7. æ‰“å°åˆå§‹åŒ–å®Œæˆä¿¡æ¯
        print(f"ğŸ¯ å®Œæ•´æŠ•èµ„ç»„åˆåˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“Š åŒ…å«è‚¡ç¥¨: {self.n_stocks}åª")  # æ˜¾ç¤ºè‚¡ç¥¨æ•°é‡
        print(f"ğŸ“… æ•°æ®æœŸé—´: {stock_returns.index[0].date()} åˆ° {stock_returns.index[-1].date()}")  # æ˜¾ç¤ºæ•°æ®èµ·æ­¢æ—¥æœŸ
        print(f"ğŸ“ˆ äº¤æ˜“æ—¥æ•°: {len(stock_returns)}")  # æ˜¾ç¤ºæ€»äº¤æ˜“æ—¥æ•°

    def _calculate_basic_stats(self):
        """è®¡ç®—åŸºç¡€ç»Ÿè®¡æŒ‡æ ‡"""
        # 1. è®¡ç®—æ¯åªè‚¡ç¥¨çš„å¹´åŒ–æ”¶ç›Šç‡ï¼šæ—¥æ”¶ç›Šç‡å‡å€¼ Ã— 252ï¼ˆå¹´åŒ–å› å­ï¼‰
        self.annual_returns = ( 1+ self.stock_returns.mean()) ** 252 - 1     # æ­£ç¡®è®¡ç®—å¹´åŒ–æ”¶ç›Šç‡
        # 2. è®¡ç®—æ¯åªè‚¡ç¥¨çš„å¹´åŒ–æ³¢åŠ¨ç‡ï¼šæ—¥æ”¶ç›Šç‡æ ‡å‡†å·® Ã— âˆš252
        self.annual_volatility = self.stock_returns.std() * np.sqrt(252)
        # 3. è®¡ç®—æ¯åªè‚¡ç¥¨çš„å¤æ™®æ¯”ç‡ï¼š(å¹´åŒ–æ”¶ç›Šç‡ - æ— é£é™©åˆ©ç‡) / å¹´åŒ–æ³¢åŠ¨ç‡
        self.sharpe_ratios = (self.annual_returns - self.risk_free_rate * 252) / self.annual_volatility
        # 4. è®¡ç®—åæ–¹å·®çŸ©é˜µï¼ˆå¹´åŒ–ï¼‰ï¼šæ—¥æ”¶ç›Šç‡åæ–¹å·® Ã— 252
        self.cov_matrix = self.stock_returns.cov() * 252
        # 5. è®¡ç®—ç›¸å…³æ€§çŸ©é˜µï¼šå„è‚¡ç¥¨æ”¶ç›Šç‡ä¹‹é—´çš„ç›¸å…³ç³»æ•°ï¼ˆ-1åˆ°1ä¹‹é—´ï¼‰
        self.corr_matrix = self.stock_returns.corr()
        # 6. è®¡ç®—ç´¯è®¡æ”¶ç›Šç‡ï¼š(1 + æ—¥æ”¶ç›Šç‡) çš„ç´¯ç§¯ä¹˜ç§¯
        self.cumulative_returns = (1 + self.stock_returns).cumprod()

    def optimize_portfolio(self, optimization_type='max_sharpe', constraints=None):
        """
                æŠ•èµ„ç»„åˆä¼˜åŒ–

                å‚æ•°:
                optimization_type: ä¼˜åŒ–ç±»å‹ ['max_sharpe', 'min_vol']
                constraints: çº¦æŸæ¡ä»¶å­—å…¸ {'max_weight': 0.3, 'min_weight': 0.01}
                """
        # 1. æ‰“å°ä¼˜åŒ–è¿‡ç¨‹å¼€å§‹ä¿¡æ¯ï¼Œä½¿ç”¨åˆ†éš”çº¿æé«˜å¯è¯»æ€§
        print(f"\n{'=' * 50}")
        print(f"ğŸ”§ æŠ•èµ„ç»„åˆä¼˜åŒ– ({optimization_type})")
        print('=' * 50)

        # 2. è®¾ç½®åˆå§‹æƒé‡ï¼šç­‰æƒé‡åˆ†é…ï¼ˆæ¯åªè‚¡ç¥¨æƒé‡ç›¸åŒï¼‰
        initial_weights = np.ones(self.n_stocks) / self.n_stocks
        # 3. å®šä¹‰æƒé‡è¾¹ç•Œï¼šé»˜è®¤æ¯åªè‚¡ç¥¨çš„æƒé‡åœ¨0åˆ°1ä¹‹é—´ï¼ˆ0-100%ï¼‰
        bounds = tuple((0, 1) for _ in range(self.n_stocks))
        # 4. å®šä¹‰åŸºæœ¬çº¦æŸæ¡ä»¶ï¼šæ‰€æœ‰æƒé‡ä¹‹å’Œå¿…é¡»ç­‰äº1ï¼ˆ100%æŠ•èµ„ï¼‰
        constraints_list = [{'type': 'eq', 'fun': lambda x: np.sum(x) - 1}]

        # 5. å¦‚æœç”¨æˆ·æä¾›äº†é¢å¤–çº¦æŸï¼Œæ›´æ–°è¾¹ç•Œæ¡ä»¶
        if constraints:
            if 'min_weight' in constraints:
                # è®¾ç½®æœ€å°æƒé‡çº¦æŸï¼ˆé¿å…æŒæœ‰æå°‘é‡è‚¡ç¥¨ï¼‰
                bounds = tuple((constraints['min_weight'], 1) for _ in range(self.n_stocks))
            if 'max_weight' in constraints:
                # è®¾ç½®æœ€å¤§æƒé‡çº¦æŸï¼ˆé¿å…è¿‡åº¦é›†ä¸­ï¼‰
                bounds = tuple((0, constraints['max_weight']) for _ in range(self.n_stocks))

        # 6. æ ¹æ®ä¼˜åŒ–ç±»å‹é€‰æ‹©ä¸åŒçš„ç›®æ ‡å‡½æ•°
        if optimization_type == 'max_sharpe':
            # 6.1 æœ€å¤§åŒ–å¤æ™®æ¯”ç‡çš„ç›®æ ‡å‡½æ•°
            def objective(weights):
                # è®¡ç®—æŠ•èµ„ç»„åˆçš„å¹´åŒ–æ”¶ç›Šç‡
                port_return = np.sum(self.annual_returns * weights)
                # è®¡ç®—æŠ•èµ„ç»„åˆçš„å¹´åŒ–æ³¢åŠ¨ç‡ï¼šâˆš(wáµ€Î£w)
                port_vol = np.sqrt(np.dot(weights.T, np.dot(self.cov_matrix, weights)))
                # è®¡ç®—å¤æ™®æ¯”ç‡
                sharpe = (port_return - self.risk_free_rate * 252) / port_vol
                # è¿”å›è´Ÿå€¼ï¼Œå› ä¸ºscipy.minimizeæ˜¯æœ€å°åŒ–å‡½æ•°
                return -sharpe

        elif optimization_type == 'min_vol':
            # 6.2 æœ€å°åŒ–æ³¢åŠ¨ç‡çš„ç›®æ ‡å‡½æ•°
            def objective(weights):
                # ç›´æ¥è®¡ç®—å¹¶è¿”å›æŠ•èµ„ç»„åˆçš„æ³¢åŠ¨ç‡
                port_vol = np.sqrt(np.dot(weights.T, np.dot(self.cov_matrix, weights)))
                return port_vol
        else:
            # 6.3 å¦‚æœè¾“å…¥äº†ä¸æ”¯æŒçš„ä¼˜åŒ–ç±»å‹ï¼ŒæŠ›å‡ºé”™è¯¯
            raise ValueError(f"ä¸æ”¯æŒçš„ä¼˜åŒ–ç±»å‹: {optimization_type}")

        # 7. ä½¿ç”¨scipyçš„minimizeå‡½æ•°æ‰§è¡Œä¼˜åŒ–è®¡ç®—
        result = minimize(
            objective,          # ç›®æ ‡å‡½æ•°ï¼ˆæœ€å¤§åŒ–å¤æ™®æˆ–æœ€å°åŒ–æ³¢åŠ¨ç‡ï¼‰
            initial_weights,    # ä¼˜åŒ–çš„èµ·å§‹ç‚¹ï¼ˆç­‰æƒé‡ï¼‰
            method='SLSQP',     # ä¼˜åŒ–ç®—æ³•ï¼šåºåˆ—äºŒæ¬¡è§„åˆ’ï¼Œé€‚åˆæœ‰çº¦æŸä¼˜åŒ–
            bounds=bounds,      # æƒé‡è¾¹ç•Œæ¡ä»¶ï¼ˆå¦‚0-1æˆ–ç”¨æˆ·å®šä¹‰çš„è¾¹ç•Œï¼‰
            constraints=constraints_list,  # ä½¿ç”¨æ­£ç¡®çš„çº¦æŸåˆ—è¡¨
            options={'maxiter': 1000, 'ftol': 1e-9}  # ä¼˜åŒ–å™¨è®¾ç½®
        )
        # 8. æ£€æŸ¥ä¼˜åŒ–æ˜¯å¦æˆåŠŸ
        if result.success:
            # 8.1 è·å–ä¼˜åŒ–å¾—åˆ°çš„æœ€ä¼˜æƒé‡
            optimal_weights = result.x
            # 8.2 å¯¹æƒé‡è¿›è¡Œå››èˆäº”å…¥ï¼Œä¿ç•™4ä½å°æ•°ï¼ˆæé«˜å¯è¯»æ€§ï¼‰
            optimal_weights = np.round(optimal_weights, 4)
            # 8.3 é‡æ–°å½’ä¸€åŒ–æƒé‡ï¼ˆç¡®ä¿æ€»å’Œä¸º100%ï¼Œå¤„ç†å››èˆäº”å…¥è¯¯å·®ï¼‰
            optimal_weights = optimal_weights / optimal_weights.sum()

            # 8.4 ä½¿ç”¨æœ€ä¼˜æƒé‡è®¡ç®—æŠ•èµ„ç»„åˆçš„å„é¡¹æŒ‡æ ‡
            # è®¡ç®—æŠ•èµ„ç»„åˆå¹´åŒ–æ”¶ç›Šç‡ï¼šæƒé‡ä¸å„è‚¡ç¥¨æ”¶ç›Šç‡çš„åŠ æƒå’Œ
            port_return = np.sum(self.annual_returns * optimal_weights)
            # è®¡ç®—æŠ•èµ„ç»„åˆå¹´åŒ–æ³¢åŠ¨ç‡ï¼šâˆš(wáµ€Î£w)
            port_vol = np.sqrt(np.dot(optimal_weights.T, np.dot(self.cov_matrix, optimal_weights)))
            # è®¡ç®—æŠ•èµ„ç»„åˆå¤æ™®æ¯”ç‡ï¼š(æ”¶ç›Š-æ— é£é™©åˆ©ç‡)/æ³¢åŠ¨ç‡
            port_sharpe = (port_return - self.risk_free_rate * 252) / port_vol

            # 8.5 æ‰“å°ä¼˜åŒ–æˆåŠŸçš„ç»“æœ
            print(f"âœ… ä¼˜åŒ–æˆåŠŸï¼")
            print(f"ğŸ“Š æŠ•èµ„ç»„åˆæ”¶ç›Šç‡: {port_return:.2%}")  # æ ¼å¼åŒ–æ˜¾ç¤ºç™¾åˆ†æ¯”
            print(f"ğŸ“Š æŠ•èµ„ç»„åˆæ³¢åŠ¨ç‡: {port_vol:.2%}")
            print(f"ğŸ“Š å¤æ™®æ¯”ç‡: {port_sharpe:.3f}")

            # 8.6 åˆ›å»ºæƒé‡å­—å…¸ï¼šå°†è‚¡ç¥¨åç§°ä¸æƒé‡å€¼å¯¹åº”
            weight_dict = dict(zip(self.stock_names, optimal_weights))

            # 8.7 å°†ä¼˜åŒ–ç»“æœæ•´ç†æˆå­—å…¸æ ¼å¼ï¼Œä¾¿äºåç»­ä½¿ç”¨
            result_dict = {
                'weights': weight_dict,             # è‚¡ç¥¨æƒé‡å­—å…¸
                'return': port_return,              # é¢„æœŸæ”¶ç›Šç‡
                'volatility': port_vol,             # é¢„æœŸæ³¢åŠ¨ç‡
                'sharpe': port_sharpe,              # å¤æ™®æ¯”ç‡
                'weights_array': optimal_weights    # æƒé‡æ•°ç»„ï¼ˆåŸå§‹æ ¼å¼ï¼‰
            }

            # 8.8 æ ¹æ®ä¼˜åŒ–ç±»å‹å°†ç»“æœå­˜å‚¨åˆ°å¯¹åº”çš„å±æ€§ä¸­
            if optimization_type == 'max_sharpe':
                self.max_sharpe_result = result_dict     # å­˜å‚¨æœ€å¤§å¤æ™®ç»“æœ
            elif optimization_type == 'min_vol':
                self.min_vol_result = result_dict            # å­˜å‚¨æœ€å°æ³¢åŠ¨ç‡ç»“æœ

            # 8.9 è¿”å›ä¼˜åŒ–ç»“æœå­—å…¸
            return result_dict
        else:
            # 9. å¦‚æœä¼˜åŒ–å¤±è´¥ï¼Œæ‰“å°é”™è¯¯ä¿¡æ¯å¹¶è¿”å›None
            print(f"âŒ ä¼˜åŒ–å¤±è´¥: {result.message}")
            return None

    def calculate_efficient_frontier(self, n_points=20):
        """è®¡ç®—æœ‰æ•ˆå‰æ²¿"""
        # 1. æ‰“å°è®¡ç®—å¼€å§‹ä¿¡æ¯
        print(f"\n{'=' * 50}")
        print("ğŸ“ˆ è®¡ç®—æœ‰æ•ˆå‰æ²¿")
        print('=' * 50)

        # 2. ç¡®å®šæœ‰æ•ˆå‰æ²¿çš„æ”¶ç›Šç‡èŒƒå›´
        # 2.1 æœ€å°æ”¶ç›Šç‡ï¼šå–æ‰€æœ‰è‚¡ç¥¨æœ€ä½æ”¶ç›Šç‡çš„80%ï¼ˆç•™æœ‰ç¼“å†²ï¼‰
        min_return = self.annual_returns.min() * 0.8
        # 2.2 æœ€å¤§æ”¶ç›Šç‡ï¼šå–æ‰€æœ‰è‚¡ç¥¨æœ€é«˜æ”¶ç›Šç‡çš„120%ï¼ˆç•™æœ‰ç¼“å†²ï¼‰
        max_return = self.annual_returns.max() * 1.2

        # 3. ç”Ÿæˆç›®æ ‡æ”¶ç›Šç‡åºåˆ—
        # åœ¨æœ€å°å’Œæœ€å¤§æ”¶ç›Šç‡ä¹‹é—´ç”Ÿæˆn_pointsä¸ªå‡åŒ€åˆ†å¸ƒçš„ç‚¹
        target_returns = np.linspace(min_return, max_return, n_points)
        # 4. åˆå§‹åŒ–å­˜å‚¨æœ‰æ•ˆå‰æ²¿ä¸Šå„ç‚¹çš„åˆ—è¡¨
        frontier_points = []

        # 5. å¯¹æ¯ä¸ªç›®æ ‡æ”¶ç›Šç‡è¿›è¡Œä¼˜åŒ–è®¡ç®—
        for target in target_returns:
            # 5.1 è®¾ç½®åˆå§‹æƒé‡ï¼ˆç­‰æƒé‡ï¼‰
            initial_weights = np.ones(self.n_stocks) / self.n_stocks
            # 5.2 è®¾ç½®æƒé‡è¾¹ç•Œï¼ˆ0åˆ°1ï¼‰
            bounds = tuple((0,1) for _ in range(self.n_stocks))
            # 5.3 è®¾ç½®çº¦æŸæ¡ä»¶ï¼šæƒé‡å’Œä¸º1 + è¾¾åˆ°ç›®æ ‡æ”¶ç›Šç‡
            constraints = [
                {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},      # æƒé‡å’Œ=1
                {'type': 'eq', 'fun': lambda x: np.sum(self.annual_returns * x) - target}    # è¾¾åˆ°ç›®æ ‡æ”¶ç›Šç‡
            ]

            # 5.4 å®šä¹‰ç›®æ ‡å‡½æ•°ï¼šæœ€å°åŒ–æ³¢åŠ¨ç‡
            def objective(weights):
                # è®¡ç®—æŠ•èµ„ç»„åˆæ³¢åŠ¨ç‡ï¼šâˆš(wáµ€Î£w)
                return np.sqrt(np.dot(weights.T, np.dot(self.cov_matrix, weights)))

            # 5.5 æ‰§è¡Œä¼˜åŒ–
            result = minimize(
                objective,                  # ç›®æ ‡å‡½æ•°ï¼ˆæœ€å°åŒ–æ³¢åŠ¨ç‡ï¼‰
                initial_weights,            # åˆå§‹æƒé‡
                method='SLSQP',             # ä¼˜åŒ–ç®—æ³•
                bounds=bounds,              # æƒé‡è¾¹ç•Œ
                constraints=constraints,    # çº¦æŸæ¡ä»¶
                options={'maxiter': 1000, 'ftol': 1e-9}      # ä¼˜åŒ–å™¨è®¾ç½®
            )

            # 5.6 å¦‚æœä¼˜åŒ–æˆåŠŸï¼Œä¿å­˜ç»“æœ
            if result.success:
                # å½’ä¸€åŒ–æƒé‡ï¼ˆå¤„ç†è®¡ç®—è¯¯å·®ï¼‰
                optimal_weights = result.x / result.x.sum()
                # è®¡ç®—å®é™…æ”¶ç›Šç‡ï¼ˆå¯èƒ½ä¸ç›®æ ‡ç•¥æœ‰å·®å¼‚ï¼‰
                port_return = np.sum(self.annual_returns * optimal_weights)
                # è®¡ç®—å®é™…æ³¢åŠ¨ç‡
                port_vol = np.sqrt(np.dot(optimal_weights.T, np.dot(self.cov_matrix, optimal_weights)))
                # è®¡ç®—å¤æ™®æ¯”ç‡
                port_sharpe = (port_return - self.risk_free_rate * 252) / port_vol

                # 5.7 å°†ç»“æœæ·»åŠ åˆ°åˆ—è¡¨ä¸­
                frontier_points.append({
                    'return': port_return,          # æ”¶ç›Šç‡
                    'volatility': port_vol,         # æ³¢åŠ¨ç‡
                    'sharpe': port_sharpe,          # å¤æ™®æ¯”ç‡
                    'weights': optimal_weights      # æƒé‡åˆ†é…
                })

        # 6. å°†ç»“æœè½¬æ¢ä¸ºDataFrameå¹¶å­˜å‚¨åˆ°å±æ€§ä¸­
        self.efficient_frontier = pd.DataFrame(frontier_points)

        # 7. æ‰“å°è®¡ç®—ç»“æœæ‘˜è¦
        print(f"âœ… æœ‰æ•ˆå‰æ²¿è®¡ç®—å®Œæˆ")
        print(f"ğŸ“Š ç‚¹æ•°: {len(self.efficient_frontier)}")
        print(
            f"ğŸ“Š æ”¶ç›Šç‡èŒƒå›´: {self.efficient_frontier['return'].min():.2%} - "
            f"{self.efficient_frontier['return'].max():.2%}")
        print(
            f"ğŸ“Š æ³¢åŠ¨ç‡èŒƒå›´: {self.efficient_frontier['volatility'].min():.2%} - "
            f"{self.efficient_frontier['volatility'].max():.2%}")

        # 8. è¿”å›æœ‰æ•ˆå‰æ²¿æ•°æ®
        return self.efficient_frontier

    def calculate_risk_metrics(self, weights):
        """
                è®¡ç®—é£é™©æŒ‡æ ‡

                å‚æ•°:
                weights: æƒé‡å­—å…¸ {è‚¡ç¥¨: æƒé‡}
                """
        # 1. æ‰“å°é£é™©æŒ‡æ ‡è®¡ç®—å¼€å§‹ä¿¡æ¯
        print(f"\n{'=' * 50}")
        print("ğŸ“Š é£é™©æŒ‡æ ‡è®¡ç®—")
        print('=' * 50)

        # 2. å°†æƒé‡å­—å…¸è½¬æ¢ä¸ºæƒé‡æ•°ç»„ï¼ˆä¿æŒä¸è‚¡ç¥¨é¡ºåºä¸€è‡´ï¼‰
        weight_array = np.array([weights[stock] for stock in self.stock_names])

        # 3. è®¡ç®—æŠ•èµ„ç»„åˆçš„åŸºæœ¬æŒ‡æ ‡
        # 3.1 å¹´åŒ–æ”¶ç›Šç‡ï¼šå„è‚¡ç¥¨æ”¶ç›Šç‡çš„åŠ æƒå¹³å‡
        port_return = np.sum(self.annual_returns * weight_array)
        # 3.2 å¹´åŒ–æ³¢åŠ¨ç‡ï¼šè€ƒè™‘åæ–¹å·®çš„åŠ æƒç»„åˆé£é™©
        port_vol = np.sqrt(np.dot(weight_array.T, np.dot(self.cov_matrix, weight_array)))
        # 3.3 å¤æ™®æ¯”ç‡ï¼šé£é™©è°ƒæ•´åçš„æ”¶ç›Š
        port_sharpe = (port_return - self.risk_free_rate * 252) / port_vol

        # 4. è®¡ç®—æŠ•èµ„ç»„åˆçš„æ—¥æ”¶ç›Šç‡åºåˆ—
        # å°†æ¯åªè‚¡ç¥¨çš„æ—¥æ”¶ç›Šç‡æŒ‰æƒé‡åŠ æƒæ±‚å’Œ
        port_returns_series = (self.stock_returns * weight_array).sum(axis=1)

        # 5. è®¡ç®—é£é™©ä»·å€¼ï¼ˆVaRï¼‰ - 95%ç½®ä¿¡åº¦
        # 5.1 è®¡ç®—æ—¥æ”¶ç›Šç‡çš„5%åˆ†ä½æ•°ï¼ˆæœ€åçš„5%æƒ…å†µï¼‰
        var_daily = np.percentile(port_returns_series, 5)
        # 5.2 å°†æ—¥VaRå¹´åŒ–ï¼šä¹˜ä»¥âˆš252
        var_95 = var_daily * np.sqrt(252)

        # 6. è®¡ç®—æœ€å¤§å›æ’¤
        # 6.1 è®¡ç®—ç´¯è®¡å‡€å€¼æ›²çº¿ï¼š(1+æ”¶ç›Šç‡)çš„ç´¯ç§¯ä¹˜ç§¯
        cumulative = (1 + port_returns_series).cumprod()
        # 6.2 è®¡ç®—å†å²æœ€é«˜ç‚¹åºåˆ—ï¼ˆæ»šåŠ¨æœ€å¤§å€¼ï¼‰
        running_max = cumulative.expanding().max()
        # 6.3 è®¡ç®—å›æ’¤ï¼šï¼ˆå½“å‰å‡€å€¼-å†å²æœ€é«˜ï¼‰/å†å²æœ€é«˜
        drawdown = (cumulative - running_max) / running_max
        # 6.4 æ‰¾åˆ°æœ€å¤§å›æ’¤ï¼ˆæœ€å°å€¼ï¼Œå› ä¸ºå›æ’¤æ˜¯è´Ÿæ•°ï¼‰
        max_drawdown = drawdown.min()

        # 7. è®¡ç®—Betaç³»æ•°ï¼ˆç³»ç»Ÿæ€§é£é™©ï¼‰
        # 7.1 å‡è®¾æŠ•èµ„ç»„åˆæœ¬èº«ä½œä¸ºå¸‚åœºåŸºå‡†ï¼ˆç®€åŒ–å¤„ç†ï¼‰
        market_returns = port_returns_series
        # 7.2 è®¡ç®—ç»„åˆæ”¶ç›Šä¸å¸‚åœºæ”¶ç›Šçš„åæ–¹å·®
        cov_with_market = np.cov(port_returns_series, market_returns)[0, 1]
        # 7.3 è®¡ç®—å¸‚åœºæ”¶ç›Šçš„æ–¹å·®
        market_var = np.var(market_returns)
        # 7.4 è®¡ç®—Betaï¼šåæ–¹å·®/æ–¹å·®
        beta = cov_with_market / market_var if market_var != 0 else 0

        # 8. è®¡ç®—ç´¢æè¯ºæ¯”ç‡ï¼ˆåªè€ƒè™‘ä¸‹è¡Œé£é™©ï¼‰
        # 8.1 ç­›é€‰å‡ºè´Ÿæ”¶ç›Šç‡ï¼ˆä¸‹è¡Œé£é™©ï¼‰
        negative_returns = port_returns_series[port_returns_series < 0]
        # 8.2 è®¡ç®—ä¸‹è¡Œæ³¢åŠ¨ç‡ï¼ˆè´Ÿæ”¶ç›Šç‡çš„æ ‡å‡†å·®ï¼‰
        if len(negative_returns) > 0:
            downside_vol = negative_returns.std() * np.sqrt(252)
        else:
            downside_vol = 0
        # 8.3 è®¡ç®—ç´¢æè¯ºæ¯”ç‡ï¼šï¼ˆæ”¶ç›Š-æ— é£é™©åˆ©ç‡ï¼‰/ä¸‹è¡Œæ³¢åŠ¨ç‡
        sortino_ratio = (port_return - self.risk_free_rate * 252) / downside_vol if downside_vol > 0 else 0

        # 9. æ•´ç†æ‰€æœ‰é£é™©æŒ‡æ ‡åˆ°å­—å…¸ä¸­
        metrics = {
            'å¹´åŒ–æ”¶ç›Šç‡': port_return,
            'å¹´åŒ–æ³¢åŠ¨ç‡': port_vol,
            'å¤æ™®æ¯”ç‡': port_sharpe,
            'ç´¢æè¯ºæ¯”ç‡': sortino_ratio,
            'VaR (95%)': var_95,
            'æœ€å¤§å›æ’¤': max_drawdown,
            'Betaç³»æ•°': beta,
            'æ­£æ”¶ç›Šå¤©æ•°æ¯”ä¾‹': (port_returns_series >0).mean(),
            'å¹³å‡æ—¥æ”¶ç›Šç‡': port_returns_series.mean(),
            'æ—¥æ”¶ç›Šç‡æ³¢åŠ¨ç‡': port_returns_series.std()
        }

        # 10. æ‰“å°å…³é”®é£é™©æŒ‡æ ‡
        print(f"ğŸ“ˆ å¹´åŒ–æ”¶ç›Šç‡: {port_return:.2%}")
        print(f"ğŸ“‰ å¹´åŒ–æ³¢åŠ¨ç‡: {port_vol:.2%}")
        print(f"ğŸ¯ å¤æ™®æ¯”ç‡: {port_sharpe:.3f}")
        print(f"ğŸ“Š ç´¢æè¯ºæ¯”ç‡: {sortino_ratio:.3f}")
        print(f"âš ï¸  æœ€å¤§å›æ’¤: {max_drawdown:.2%}")
        print(f"ğŸ’¸ VaR (95%): {var_95:.2%}")
        print(f"ğŸ“Š Betaç³»æ•°: {beta:.3f}")
        print(f"ğŸ“ˆ æ­£æ”¶ç›Šå¤©æ•°æ¯”ä¾‹: {(port_returns_series > 0).mean():.1%}")

        # 11. è¿”å›é£é™©æŒ‡æ ‡å­—å…¸
        return metrics

    def calculate_risk_contribution(self, weights):
        """
                è®¡ç®—é£é™©è´¡çŒ® (Brinsonæ¨¡å‹)

                å‚æ•°:
                weights: æƒé‡å­—å…¸ {è‚¡ç¥¨: æƒé‡}
                """
        # 1. æ‰“å°é£é™©è´¡çŒ®åˆ†æå¼€å§‹ä¿¡æ¯
        print(f"\n{'=' * 50}")
        print("ğŸ“Š é£é™©è´¡çŒ®åˆ†æ (Brinsonæ¨¡å‹)")
        print('=' * 50)

        # 2. å°†æƒé‡å­—å…¸è½¬æ¢ä¸ºæƒé‡æ•°ç»„ï¼ˆä¿æŒè‚¡ç¥¨é¡ºåºä¸€è‡´ï¼‰
        weight_array = np.array([weights[stock] for stock in self.stock_names])

        # 3. è®¡ç®—æŠ•èµ„ç»„åˆçš„æ€»é£é™©ï¼ˆæ³¢åŠ¨ç‡ï¼‰
        # 3.1 è®¡ç®—æŠ•èµ„ç»„åˆæ–¹å·®ï¼šwáµ€Î£w
        portfolio_variance = np.dot(weight_array.T, np.dot(self.cov_matrix, weight_array))
        # 3.2 è®¡ç®—æŠ•èµ„ç»„åˆæ³¢åŠ¨ç‡ï¼ˆæ ‡å‡†å·®ï¼‰ï¼šâˆšæ–¹å·®
        portfolio_volatility = np.sqrt(portfolio_variance)

        # 4. è®¡ç®—è¾¹é™…é£é™©è´¡çŒ®
        # è¾¹é™…é£é™©è´¡çŒ® = Î£w / Ïƒâ‚š ï¼ˆåæ–¹å·®çŸ©é˜µä¸æƒé‡çš„ä¹˜ç§¯é™¤ä»¥æ€»æ³¢åŠ¨ç‡ï¼‰
        marginal_risk = self.cov_matrix @ weight_array / portfolio_volatility

        # 5. è®¡ç®—ç»å¯¹é£é™©è´¡çŒ®
        # ç»å¯¹é£é™©è´¡çŒ® = æƒé‡ Ã— è¾¹é™…é£é™©è´¡çŒ®
        absolute_contributions = weight_array * marginal_risk

        # 6. è®¡ç®—ç›¸å¯¹é£é™©è´¡çŒ®ï¼ˆç™¾åˆ†æ¯”ï¼‰
        # 6.1 è®¡ç®—æ€»é£é™©è´¡çŒ®ï¼ˆæ‰€æœ‰ç»å¯¹é£é™©è´¡çŒ®ä¹‹å’Œï¼‰
        total_risk_contribution = np.sum(absolute_contributions)
        # 6.2 è®¡ç®—æ¯åªè‚¡ç¥¨çš„ç›¸å¯¹é£é™©è´¡çŒ®
        relative_contributions = absolute_contributions / total_risk_contribution

        # 7. åˆ›å»ºé£é™©è´¡çŒ®åˆ†æDataFrame
        risk_df = pd.DataFrame({
            'è‚¡ç¥¨': self.stock_names,                      # è‚¡ç¥¨åç§°
            'æƒé‡': weight_array,                          # æŠ•èµ„æƒé‡
            'å¹´åŒ–æ³¢åŠ¨ç‡': self.annual_volatility.values,     # ä¸ªè‚¡æ³¢åŠ¨ç‡
            'ç»å¯¹é£é™©è´¡çŒ®': absolute_contributions,           # å¯¹ç»„åˆé£é™©çš„ç»å¯¹è´¡çŒ®
            'ç›¸å¯¹é£é™©è´¡çŒ®': relative_contributions,           # å¯¹ç»„åˆé£é™©çš„ç›¸å¯¹è´¡çŒ®ï¼ˆ%ï¼‰
            'é£é™©å€æ•°': relative_contributions / weight_array       # é£é™©è´¡çŒ®/æƒé‡ æ¯”å€¼
        })

        # 8. æŒ‰ç›¸å¯¹é£é™©è´¡çŒ®ä»é«˜åˆ°ä½æ’åº
        risk_df = risk_df.sort_values('ç›¸å¯¹é£é™©è´¡çŒ®', ascending=False)

        # 9. æ‰“å°é£é™©è´¡çŒ®åˆ†æç»“æœ
        print(f"ğŸ“Š æ€»æŠ•èµ„ç»„åˆé£é™©: {portfolio_volatility:.2%}")
        print(f"ğŸ“Š æ€»é£é™©è´¡çŒ®: {total_risk_contribution:.2%}")
        print(f"\nğŸ¯ å‰5å¤§é£é™©è´¡çŒ®è€…:")

        # 10. æ˜¾ç¤ºå‰5å¤§é£é™©æ¥æº
        for i, row in risk_df.head(5).iterrows():
            print(f"  {row['è‚¡ç¥¨']}: æƒé‡{row['æƒé‡']:.1%}, é£é™©è´¡çŒ®{row['ç›¸å¯¹é£é™©è´¡çŒ®']:.1%}, é£é™©å€æ•°{row['é£é™©å€æ•°']:.2f}x")

        # 11. è¯†åˆ«é«˜é£é™©å’Œä½é£é™©è‚¡ç¥¨
        # 11.1 é«˜é£é™©è‚¡ç¥¨ï¼šé£é™©å€æ•° > 1.5ï¼ˆé£é™©è´¡çŒ®æ˜¾è‘—é«˜äºæƒé‡ï¼‰
        high_risk = risk_df[risk_df['é£é™©å€æ•°'] > 1.5]
        # 11.2 ä½é£é™©è‚¡ç¥¨ï¼šé£é™©å€æ•° < 0.7ï¼ˆé£é™©è´¡çŒ®æ˜¾è‘—ä½äºæƒé‡ï¼‰
        low_risk = risk_df[risk_df['é£é™©å€æ•°'] < 0.7]

        # 12. è¾“å‡ºé«˜é£é™©è‚¡ç¥¨è­¦å‘Š
        if len(high_risk) > 0:
            print(f"\nâš ï¸  é«˜é£é™©è‚¡ç¥¨ (é£é™©è´¡çŒ®æ˜¾è‘—é«˜äºæƒé‡):")
            for _, row in high_risk.iterrows():
                print(f"  {row['è‚¡ç¥¨']}: é£é™©å€æ•°{row['é£é™©å€æ•°']:.2f}x")

        # 13. è¾“å‡ºä½é£é™©è‚¡ç¥¨ä¿¡æ¯
        if len(low_risk) > 0:
            print(f"\nâœ… ä½é£é™©è‚¡ç¥¨ (é£é™©è´¡çŒ®æ˜¾è‘—ä½äºæƒé‡):")
            for _, row in low_risk.iterrows():
                print(f"  {row['è‚¡ç¥¨']}: é£é™©å€æ•°{row['é£é™©å€æ•°']:.2f}x")

        # 14. è®¡ç®—é£é™©é›†ä¸­åº¦æŒ‡æ•°ï¼ˆèµ«èŠ¬è¾¾å°”-èµ«å¸Œæ›¼æŒ‡æ•°ï¼‰
        # é£é™©è´¡çŒ®ç™¾åˆ†æ¯”çš„å¹³æ–¹å’Œï¼Œå€¼è¶Šå¤§è¡¨ç¤ºé£é™©è¶Šé›†ä¸­
        herfindahl_index = (risk_df['ç›¸å¯¹é£é™©è´¡çŒ®'] ** 2).sum()
        print(f"\nğŸ“Š é£é™©é›†ä¸­åº¦æŒ‡æ•°: {herfindahl_index:.3f}")

        # 15. æ ¹æ®é£é™©é›†ä¸­åº¦ç»™å‡ºå»ºè®®
        if herfindahl_index > 0.25:
            print("  ğŸ¯ é£é™©é›†ä¸­åº¦è¾ƒé«˜ï¼Œå»ºè®®è¿›ä¸€æ­¥åˆ†æ•£")
        elif herfindahl_index > 0.15:
            print("  ğŸ¯ é£é™©é›†ä¸­åº¦é€‚ä¸­")
        else:
            print("  ğŸ¯ é£é™©åˆ†æ•£åº¦è‰¯å¥½")

        # 16. è¿”å›é£é™©è´¡çŒ®åˆ†æDataFrame
        return risk_df

    def backtest_portfolio(self, weights, initial_capital=10000, rebalance_freq='Q'):
        """
                å›æµ‹æŠ•èµ„ç»„åˆè¡¨ç°

                å‚æ•°:
                weights: æƒé‡å­—å…¸
                initial_capital: åˆå§‹èµ„æœ¬
                rebalance_freq: å†å¹³è¡¡é¢‘ç‡ ['M'=æœˆ, 'Q'=å­£, 'Y'=å¹´]
                """
        # 1. æ‰“å°å›æµ‹å¼€å§‹ä¿¡æ¯
        print(f"\n{'=' * 50}")
        print(f"ğŸ“ˆ æŠ•èµ„ç»„åˆå›æµ‹åˆ†æ")
        print('=' * 50)

        # 2. å‡†å¤‡æ•°æ®
        returns = self.stock_returns.copy()     # å¤åˆ¶æ”¶ç›Šç‡æ•°æ®ï¼Œé¿å…ä¿®æ”¹åŸæ•°æ®
        weight_array = np.array([weights[stock] for stock in self.stock_names]) # æƒé‡æ•°ç»„

        # 3. åˆå§‹åŒ–å˜é‡
        current_weights = weight_array.copy()    # å½“å‰æƒé‡ï¼ˆéšæ—¶é—´å˜åŒ–ï¼‰
        capital = initial_capital            # å½“å‰èµ„æœ¬
        capital_history = [capital]          # èµ„æœ¬å†å²è®°å½•
        date_history = [returns.index[0]]   # æ—¥æœŸå†å²è®°å½•
        weight_history = [current_weights.copy()]    # æƒé‡å†å²è®°å½•

        # 4. ç¡®å®šå†å¹³è¡¡é¢‘ç‡
        # æ ¹æ®è¾“å…¥å‚æ•°è®¾ç½®pandasçš„é‡é‡‡æ ·é¢‘ç‡
        if rebalance_freq == 'M':
            freq = 'MS'     # æ¯æœˆå¼€å§‹
        elif rebalance_freq == 'Q':
            freq = 'QS'     # æ¯å­£å¼€å§‹
        elif rebalance_freq == 'Y':
            freq = 'YS'     # æ¯å¹´å¼€å§‹
        else:
            freq = 'QS'     # é»˜è®¤å­£åº¦å†å¹³è¡¡

        # 5. ç”Ÿæˆå†å¹³è¡¡æ—¥æœŸåºåˆ—
        # ä»æ•°æ®å¼€å§‹åˆ°ç»“æŸï¼ŒæŒ‰æŒ‡å®šé¢‘ç‡ç”Ÿæˆå†å¹³è¡¡æ—¥æœŸ
        rebalance_dates = pd.date_range(
            start=returns.index[0],
            end=returns.index[-1],
            freq=freq
        )

        # 6. æ‰§è¡Œå›æµ‹ï¼ˆé€æ—¥æ¨¡æ‹Ÿï¼‰
        rebalance_count = 0 # å†å¹³è¡¡æ¬¡æ•°è®¡æ•°å™¨
        for i in range(1, len(returns)):        # ä»ç¬¬2å¤©å¼€å§‹
            current_date = returns.index[i]      # å½“å‰æ—¥æœŸ
            # 6.1 è®¡ç®—å½“æ—¥æŠ•èµ„ç»„åˆæ”¶ç›Šç‡ï¼šå„è‚¡ç¥¨æ”¶ç›Šç‡æŒ‰æƒé‡åŠ æƒæ±‚å’Œ
            daily_return = np.sum(returns.iloc[i] * current_weights)
            # 6.2 æ›´æ–°èµ„æœ¬ï¼šæŒ‰æ”¶ç›Šç‡å¢é•¿
            capital *= (1 + daily_return)
            # 6.3 è®°å½•å†å²æ•°æ®
            capital_history.append(capital)
            date_history.append(current_date)
            weight_history.append(current_weights.copy())
            # 6.4 æ£€æŸ¥æ˜¯å¦éœ€è¦å†å¹³è¡¡
            if current_date in rebalance_dates:
                # æ¢å¤ä¸ºç›®æ ‡æƒé‡ï¼ˆå†å¹³è¡¡ï¼‰
                current_weights = weight_array.copy()
                rebalance_count += 1    # è®¡æ•°åŠ 1

        # 7. åˆ›å»ºå›æµ‹ç»“æœDataFrame
        backtest_df = pd.DataFrame({
            'date': date_history,           # æ—¥æœŸåºåˆ—
            'capital': capital_history      # èµ„æœ¬åºåˆ—
        }).set_index('date')            # è®¾ç½®æ—¥æœŸä¸ºç´¢å¼•

        # 8. è®¡ç®—å›æµ‹ç»©æ•ˆæŒ‡æ ‡
        # 8.1 æ€»æ”¶ç›Šç‡ï¼šï¼ˆæœ€ç»ˆèµ„æœ¬/åˆå§‹èµ„æœ¬ï¼‰-1
        total_return = (capital_history[-1] / initial_capital) - 1
        # 8.2 å¹´åŒ–æ”¶ç›Šç‡ï¼š(1+æ€»æ”¶ç›Šç‡)^(252/å¤©æ•°) - 1
        annualized_return = ( 1+ total_return) ** (252/len(returns)) - 1
        # 8.3 è®¡ç®—æ—¥æ”¶ç›Šç‡åºåˆ—ï¼ˆç”¨äºè®¡ç®—æ³¢åŠ¨ç‡ï¼‰
        returns_series = backtest_df['capital'].pct_change().dropna()
        # 8.4 å¹´åŒ–æ³¢åŠ¨ç‡ï¼šæ—¥æ”¶ç›Šç‡æ ‡å‡†å·®Ã—âˆš252
        volatility = returns_series.std() * np.sqrt(252)
        # 8.5 å¤æ™®æ¯”ç‡ï¼šï¼ˆå¹´åŒ–æ”¶ç›Š-æ— é£é™©åˆ©ç‡ï¼‰/æ³¢åŠ¨ç‡
        sharpe = (annualized_return - self.risk_free_rate * 252) / volatility

        # 9. è®¡ç®—æœ€å¤§å›æ’¤
        # 9.1 è®¡ç®—ç´¯è®¡å‡€å€¼
        cumulative = (1 + returns_series).cumprod()
        # 9.2 è®¡ç®—å†å²æœ€é«˜ç‚¹ï¼ˆæ»šåŠ¨æœ€å¤§å€¼ï¼‰
        running_max = cumulative.expanding().max()
        # 9.3 è®¡ç®—å›æ’¤ç‡
        drawdown = (cumulative - running_max) / running_max
        # 9.4 æ‰¾åˆ°æœ€å¤§å›æ’¤ï¼ˆæœ€å°å€¼ï¼‰
        max_drawdown = drawdown.min()
        # 9.5 æ‰¾åˆ°æœ€å¤§å›æ’¤å‘ç”Ÿæ—¥æœŸ
        max_dd_period = (drawdown == max_drawdown).idxmax() if len(drawdown) > 0 else None

        # 10. æ•´ç†å›æµ‹æŒ‡æ ‡åˆ°å­—å…¸
        backtest_metrics = {
            'æ€»æ”¶ç›Šç‡': total_return,                       # æ•´ä¸ªæœŸé—´çš„æ€»æ”¶ç›Š
            'å¹´åŒ–æ”¶ç›Šç‡': annualized_return,                 # æŠ˜ç®—åˆ°æ¯å¹´çš„æ”¶ç›Š
            'å¹´åŒ–æ³¢åŠ¨ç‡': volatility,                        # é£é™©æ°´å¹³
            'å¤æ™®æ¯”ç‡': sharpe,                             # é£é™©è°ƒæ•´åæ”¶ç›Š
            'æœ€å¤§å›æ’¤': max_drawdown,                       # æœ€å¤§äºæŸå¹…åº¦
            'æœ€å¤§å›æ’¤æ—¥æœŸ': max_dd_period,                    # æœ€å¤§å›æ’¤å‘ç”Ÿæ—¶é—´
            'æœ€ç»ˆèµ„æœ¬': capital_history[-1],                # å›æµ‹ç»“æŸæ—¶çš„èµ„æœ¬
            'å†å¹³è¡¡æ¬¡æ•°': rebalance_count,                   # å†å¹³è¡¡æ“ä½œæ¬¡æ•°
            'ç›ˆåˆ©å¤©æ•°æ¯”ä¾‹': (returns_series > 0).mean(),      # èµšé’±å¤©æ•°æ¯”ä¾‹
            'æœ€å¤§å•æ—¥æ¶¨å¹…': returns_series.max(),             # æœ€å¥½çš„ä¸€å¤©
            'æœ€å¤§å•æ—¥è·Œå¹…': returns_series.min(),             # æœ€å·®çš„ä¸€å¤©
            'å¹³å‡æ—¥æ”¶ç›Šç‡': returns_series.mean()             # æ—¥å‡æ”¶ç›Š
        }

        # 11. æ‰“å°å›æµ‹ç»“æœ
        print(f"ğŸ’° åˆå§‹èµ„æœ¬: ${initial_capital:,}")
        print(f"ğŸ’° æœ€ç»ˆèµ„æœ¬: ${capital_history[-1]:,.2f}")
        print(f"ğŸ“ˆ æ€»æ”¶ç›Šç‡: {total_return:.2%}")
        print(f"ğŸ“ˆ å¹´åŒ–æ”¶ç›Šç‡: {annualized_return:.2%}")
        print(f"ğŸ“‰ å¹´åŒ–æ³¢åŠ¨ç‡: {volatility:.2%}")
        print(f"ğŸ¯ å¤æ™®æ¯”ç‡: {sharpe:.3f}")
        print(f"âš ï¸  æœ€å¤§å›æ’¤: {max_drawdown:.2%}")
        if max_dd_period:
            print(f"ğŸ“… æœ€å¤§å›æ’¤æ—¥æœŸ: {max_dd_period.date()}")
        print(f"ğŸ”„ å†å¹³è¡¡æ¬¡æ•°: {rebalance_count}")
        print(f"ğŸ“Š ç›ˆåˆ©å¤©æ•°æ¯”ä¾‹: {(returns_series > 0).mean():.1%}")
        print(f"ğŸ“ˆ æœ€å¤§å•æ—¥æ¶¨å¹…: {returns_series.max():.2%}")
        print(f"ğŸ“‰ æœ€å¤§å•æ—¥è·Œå¹…: {returns_series.min():.2%}")

        # 12. è¿”å›å›æµ‹æ•°æ®å’ŒæŒ‡æ ‡
        return backtest_df, backtest_metrics

    def generate_comprehensive_report(self, weights, benchmark_weights=None):
        """
                ç”Ÿæˆå®Œæ•´çš„æŠ•èµ„ç»„åˆåˆ†ææŠ¥å‘Š

                å‚æ•°:
                weights: æŠ•èµ„ç»„åˆæƒé‡
                benchmark_weights: åŸºå‡†ç»„åˆæƒé‡ (å¯é€‰)
                """
        # 1. æ‰“å°æŠ¥å‘Šç”Ÿæˆå¼€å§‹ä¿¡æ¯
        print(f"\n{'=' * 80}")
        print("ğŸ“‹ æŠ•èµ„ç»„åˆç»¼åˆåˆ†ææŠ¥å‘Š")
        print("=" * 80)

        # 2. ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
        print("\n1ï¸âƒ£ åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯")
        print("-" * 40)

        # 2.1 åˆ›å»ºåŸºæœ¬ç»Ÿè®¡DataFrame
        stats_df = pd.DataFrame({
            'è‚¡ç¥¨': self.stock_names, # è‚¡ç¥¨åç§°
            'å¹´åŒ–æ”¶ç›Šç‡': [self.annual_returns[s] for s in self.stock_names],    # å„è‚¡ç¥¨å¹´åŒ–æ”¶ç›Š
            'å¹´åŒ–æ³¢åŠ¨ç‡': [self.annual_volatility[s] for s in self.stock_names],  # å„è‚¡ç¥¨å¹´åŒ–æ³¢åŠ¨
            'å¤æ™®æ¯”ç‡': [self.sharpe_ratios[s] for s in self.stock_names],      # å„è‚¡ç¥¨å¤æ™®æ¯”ç‡
            'æƒé‡': [weights.get(s, 0) for s in self.stock_names]     # æŠ•èµ„ç»„åˆä¸­çš„æƒé‡
        })

        # 2.2 å¦‚æœæœ‰åŸºå‡†æƒé‡ï¼Œæ·»åŠ åŸºå‡†ç›¸å…³åˆ—
        if benchmark_weights:
            stats_df['åŸºå‡†æƒé‡'] = [benchmark_weights.get(s, 0) for s in self.stock_names]
            stats_df['ä¸»åŠ¨æƒé‡'] = stats_df['æƒé‡'] - stats_df['åŸºå‡†æƒé‡']     # ä¸»åŠ¨ç®¡ç†éƒ¨åˆ†

        # 2.3 æ˜¾ç¤ºå‰10åªè‚¡ç¥¨ï¼ˆæŒ‰æƒé‡é™åºï¼‰
        print(stats_df.sort_values('æƒé‡', ascending=False).head(10).round(4).to_string())

        # 3. ç¬¬äºŒéƒ¨åˆ†ï¼šæŠ•èµ„ç»„åˆæŒ‡æ ‡
        print("\n2ï¸âƒ£ æŠ•èµ„ç»„åˆæŒ‡æ ‡")
        print("-" * 40)
        # è°ƒç”¨ä¹‹å‰å®šä¹‰çš„calculate_risk_metricsæ–¹æ³•è®¡ç®—é£é™©æŒ‡æ ‡
        port_metrics = self.calculate_risk_metrics(weights)

        # 4. ç¬¬ä¸‰éƒ¨åˆ†ï¼šé£é™©è´¡çŒ®åˆ†æ
        print("\n3ï¸âƒ£ é£é™©è´¡çŒ®åˆ†æ")
        print("-" * 40)
        # è°ƒç”¨ä¹‹å‰å®šä¹‰çš„calculate_risk_contributionæ–¹æ³•åˆ†æé£é™©è´¡çŒ®
        risk_df = self.calculate_risk_contribution(weights)

        # 5. ç¬¬å››éƒ¨åˆ†ï¼šå›æµ‹ç»“æœ
        print("\n4ï¸âƒ£ å›æµ‹ç»“æœ")
        print("-" * 40)
        # è°ƒç”¨ä¹‹å‰å®šä¹‰çš„backtest_portfolioæ–¹æ³•è¿›è¡Œå›æµ‹
        backtest_df, backtest_metrics = self.backtest_portfolio(weights)

        # 6. ç¬¬äº”éƒ¨åˆ†ï¼šä¼˜åŒ–å¯¹æ¯”
        print("\n5ï¸âƒ£ ä¼˜åŒ–å¯¹æ¯”")
        print("-" * 40)

        # 6.1 å¦‚æœå·²ç»è®¡ç®—äº†æœ€å¤§å¤æ™®ç»„åˆï¼Œæ˜¾ç¤ºå¯¹æ¯”
        if self.max_sharpe_result:
            print(f"ğŸ¯ æœ€å¤§å¤æ™®ç»„åˆ:")
            print(f"   æ”¶ç›Šç‡: {self.max_sharpe_result['return']:.2%}")
            print(f"   æ³¢åŠ¨ç‡: {self.max_sharpe_result['volatility']:.2%}")
            print(f"   å¤æ™®æ¯”ç‡: {self.max_sharpe_result['sharpe']:.3f}")

            # 6.2 è·å–å½“å‰é…ç½®çš„æŒ‡æ ‡
            current_return = port_metrics['å¹´åŒ–æ”¶ç›Šç‡']
            current_vol = port_metrics['å¹´åŒ–æ³¢åŠ¨ç‡']
            current_sharpe = port_metrics['å¤æ™®æ¯”ç‡']

            # 6.3 å¯¹æ¯”å½“å‰é…ç½®ä¸æœ€ä¼˜é…ç½®
            print(f"\nğŸ“Š å½“å‰é…ç½® vs æœ€ä¼˜é…ç½®:")
            print(f"   æ”¶ç›Šç‡å·®è·: {current_return - self.max_sharpe_result['return']:+.2%}")
            print(f"   æ³¢åŠ¨ç‡å·®è·: {current_vol - self.max_sharpe_result['volatility']:+.2%}")
            print(f"   å¤æ™®æ¯”ç‡å·®è·: {current_sharpe - self.max_sharpe_result['sharpe']:+.3f}")

        # 7. ç¬¬å…­éƒ¨åˆ†ï¼šæŠ•èµ„å»ºè®®
        print("\n6ï¸âƒ£ æŠ•èµ„å»ºè®®")
        print("-" * 40)
        # è°ƒç”¨ç”ŸæˆæŠ•èµ„å»ºè®®çš„æ–¹æ³•
        self.generate_investment_advice(weights, risk_df, port_metrics)

        # 8. æ‰“å°æŠ¥å‘Šå®Œæˆä¿¡æ¯
        print("\n" + "=" * 80)
        print("ğŸ“‹ æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
        print("=" * 80)

        # 9. è¿”å›æ‰€æœ‰åˆ†æç»“æœï¼ˆä¾¿äºè¿›ä¸€æ­¥å¤„ç†ï¼‰
        return {
            'stats': stats_df,              # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
            'portfolio_metrics': port_metrics, # æŠ•èµ„ç»„åˆæŒ‡æ ‡
            'risk_analysis': risk_df,       # é£é™©è´¡çŒ®åˆ†æ
            'backtest_metrics': backtest_metrics,    # å›æµ‹æŒ‡æ ‡
            'backtest_data': backtest_df         # å›æµ‹æ•°æ®
        }

    def generate_investment_advice(self, weights, risk_df, port_metrics):
        """ç”ŸæˆæŠ•èµ„å»ºè®®"""
        # 1. åˆ†æé«˜é£é™©è‚¡ç¥¨ï¼ˆé£é™©å€æ•° > 1.5ï¼‰
        # é£é™©å€æ•° = ç›¸å¯¹é£é™©è´¡çŒ® / æƒé‡ï¼Œ>1.5è¡¨ç¤ºé£é™©è´¡çŒ®æ˜¾è‘—é«˜äºæƒé‡
        high_risk_stocks = risk_df[risk_df['é£é™©å€æ•°'] > 1.5]
        # åˆ†æä½é£é™©è‚¡ç¥¨ï¼ˆé£é™©å€æ•° < 0.7ï¼‰
        low_risk_stocks = risk_df[risk_df['é£é™©å€æ•°'] < 0.7]

        # 2. é«˜é£é™©è‚¡ç¥¨å»ºè®®ï¼ˆå»ºè®®å‡ä»“ï¼‰
        if len(high_risk_stocks) > 0:
            print(f"âš ï¸  å»ºè®®å‡ä»“çš„è‚¡ç¥¨ (é£é™©è¿‡é«˜):")
            for _, row in high_risk_stocks.iterrows():
                current_weight = row['æƒé‡']  # å½“å‰æƒé‡
                # å»ºè®®æƒé‡ï¼šé™ä½åˆ°é£é™©å€æ•°=1çš„æ°´å¹³ï¼ˆé£é™©è´¡çŒ®ä¸æƒé‡åŒ¹é…ï¼‰
                suggested_weight = current_weight / row['é£é™©å€æ•°']
                # è®¡ç®—éœ€è¦å‡å°‘çš„ç™¾åˆ†æ¯”
                reduction = (current_weight - suggested_weight) * 100
                print(f"  {row['è‚¡ç¥¨']}: å½“å‰{current_weight:.1%} â†’ å»ºè®®{suggested_weight:.1%} (å‡å°‘{reduction:.1f}%)")

        # 3. ä½é£é™©è‚¡ç¥¨å»ºè®®ï¼ˆå»ºè®®åŠ ä»“ï¼‰
        if len(low_risk_stocks) > 0:
            print(f"\nâœ… å»ºè®®åŠ ä»“çš„è‚¡ç¥¨ (é£é™©åˆ©ç”¨ä¸è¶³):")
            for _, row in low_risk_stocks.iterrows():
                current_weight = row['æƒé‡']  # å½“å‰æƒé‡
                # å»ºè®®æƒé‡ï¼šå¢åŠ 50%ï¼ˆå……åˆ†åˆ©ç”¨ä½é£é™©ç‰¹æ€§ï¼‰
                suggested_weight = current_weight * 1.5
                # è®¡ç®—éœ€è¦å¢åŠ çš„ç™¾åˆ†æ¯”
                increase = (suggested_weight - current_weight) * 100
                print(f"  {row['è‚¡ç¥¨']}: å½“å‰{current_weight:.1%} â†’ å»ºè®®{suggested_weight:.1%} (å¢åŠ {increase:.1f}%)")

        # 4. åŸºäºå¤æ™®æ¯”ç‡çš„å»ºè®®
        current_sharpe = port_metrics['å¤æ™®æ¯”ç‡']    # å½“å‰æŠ•èµ„ç»„åˆçš„å¤æ™®æ¯”ç‡

        if current_sharpe < 0.5:
            print(f"\nğŸ¯ é£é™©è°ƒæ•´æ”¶ç›Šåä½ (å¤æ™®æ¯”ç‡{current_sharpe:.3f})")
            print("  å»ºè®®: å¢åŠ ä½æ³¢åŠ¨èµ„äº§ï¼Œå‡å°‘é«˜é£é™©è‚¡ç¥¨")
        elif current_sharpe < 1.0:
            print(f"\nğŸ¯ é£é™©è°ƒæ•´æ”¶ç›Šé€‚ä¸­ (å¤æ™®æ¯”ç‡{current_sharpe:.3f})")
            print("  å»ºè®®: ä¿æŒå½“å‰é…ç½®ï¼Œå®šæœŸå†å¹³è¡¡")
        else:
            print(f"\nğŸ¯ é£é™©è°ƒæ•´æ”¶ç›Šä¼˜ç§€ (å¤æ™®æ¯”ç‡{current_sharpe:.3f})")
            print("  å»ºè®®: å½“å‰é…ç½®è‰¯å¥½ï¼Œç»§ç»­æŒæœ‰")

        # 5. åŸºäºæœ€å¤§å›æ’¤çš„å»ºè®®
        max_dd = port_metrics['æœ€å¤§å›æ’¤']       # å½“å‰æŠ•èµ„ç»„åˆçš„æœ€å¤§å›æ’¤

        if max_dd < -0.20:  # æœ€å¤§å›æ’¤è¶…è¿‡-20%
            print(f"\nâš ï¸  é£é™©æ§åˆ¶éœ€è¦åŠ å¼º (æœ€å¤§å›æ’¤{max_dd:.2%})")
            print("  å»ºè®®: è®¾ç½®æ­¢æŸï¼Œå¢åŠ é˜²å¾¡æ€§èµ„äº§")
        elif max_dd < -0.10:    # æœ€å¤§å›æ’¤åœ¨-10%åˆ°-20%ä¹‹é—´
            print(f"\nğŸ“Š é£é™©æ§åˆ¶é€‚ä¸­ (æœ€å¤§å›æ’¤{max_dd:.2%})")
            print("  å»ºè®®: ç›‘æ§é«˜é£é™©èµ„äº§ï¼Œä¿æŒæµåŠ¨æ€§")
        else:   # æœ€å¤§å›æ’¤å°äº-10%
            print(f"\nâœ… é£é™©æ§åˆ¶ä¼˜ç§€ (æœ€å¤§å›æ’¤{max_dd:.2%})")
            print("  å»ºè®®: å½“å‰é£é™©æ§åˆ¶è‰¯å¥½")

        # 6. æ€»ä½“å»ºè®®
        print(f"\nğŸ”§ æ€»ä½“å»ºè®®:")
        print("  1. æ¯å­£åº¦é‡æ–°å¹³è¡¡æŠ•èµ„ç»„åˆ")
        print("  2. å®šæœŸç›‘æ§é£é™©è´¡çŒ®åº¦")
        print("  3. å…³æ³¨é«˜é£é™©è‚¡ç¥¨çš„è¡¨ç°")
        print("  4. æ ¹æ®å¸‚åœºç¯å¢ƒè°ƒæ•´é£é™©é¢„ç®—")

    def plot_comprehensive_analysis(self, weights, backtest_df=None):
        """
                ç»˜åˆ¶å®Œæ•´çš„åˆ†æå›¾è¡¨ (5å¼ åˆ†å›¾)

                å‚æ•°:
                weights: æŠ•èµ„ç»„åˆæƒé‡
                backtest_df: å›æµ‹æ•°æ®
                """
        # 1. æ‰“å°å›¾è¡¨ç”Ÿæˆå¼€å§‹ä¿¡æ¯
        print(f"\n{'=' * 50}")
        print("ğŸ¨ ç”Ÿæˆåˆ†æå›¾è¡¨ (5å¼ åˆ†å›¾)")
        print('=' * 50)

        # ==================== å›¾1: æƒé‡å’Œæ”¶ç›Šæ³¢åŠ¨ ====================
        # åˆ›å»ºç¬¬ä¸€ä¸ªå›¾å½¢ï¼ˆ1è¡Œ2åˆ—ï¼‰
        fig1, (ax1, ax2) = plt.subplots(1,2, figsize=(16,6))
        fig1.suptitle('å›¾1: æŠ•èµ„ç»„åˆæƒé‡å’Œæ”¶ç›Šæ³¢åŠ¨åˆ†æ', fontsize=16, fontweight='bold')

        # 1.1 æƒé‡åˆ†å¸ƒå›¾ï¼ˆå·¦å›¾ï¼‰
        # å°†æƒé‡è½¬æ¢ä¸ºSerieså¹¶æŒ‰æƒé‡é™åºæ’åº
        weight_series = pd.Series(weights).sort_values(ascending=False)
        # ç”Ÿæˆé¢œè‰²ï¼šä½¿ç”¨Set3é¢œè‰²æ˜ å°„ï¼Œä¸ºæ¯åªè‚¡ç¥¨ç”Ÿæˆä¸åŒé¢œè‰²
        colors = plt.cm.Set3(np.linspace(0, 1, len(weight_series)))
        # ç»˜åˆ¶æŸ±çŠ¶å›¾
        bars = ax1.bar(range(len(weight_series)), weight_series.values, color=colors)

        # è®¾ç½®å›¾è¡¨å±æ€§
        ax1.set_title('æŠ•èµ„ç»„åˆæƒé‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax1.set_xlabel('è‚¡ç¥¨')
        ax1.set_ylabel('æƒé‡ (%)')
        ax1.set_xticks(range(len(weight_series)))
        ax1.set_xticklabels(weight_series.index, rotation=45, ha='right')
        ax1.grid(True, alpha=0.3, axis='y')

        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾ï¼ˆæƒé‡å¤§äº1%æ‰æ˜¾ç¤ºï¼‰
        for i, (bar, weight) in enumerate(zip(bars, weight_series.values)):
            if weight > 0.01:    # åªæ˜¾ç¤ºæƒé‡å¤§äº1%çš„æ ‡ç­¾
                ax1.text(i, weight + 0.01, f'{weight:.1%}',      # åœ¨æŸ±å­ä¸Šæ–¹æ˜¾ç¤ºç™¾åˆ†æ¯”
                         ha='center', va='bottom', fontsize=8, fontweight='bold')

        # 1.2 æ”¶ç›Šç‡vsæ³¢åŠ¨ç‡æ•£ç‚¹å›¾ï¼ˆå³å›¾ï¼‰
        # ç»˜åˆ¶æ•£ç‚¹å›¾ï¼šx=æ³¢åŠ¨ç‡ï¼Œy=æ”¶ç›Šç‡ï¼Œç‚¹å¤§å°=å¤æ™®æ¯”ç‡Ã—300
        scatter = ax2.scatter(self.annual_volatility, self.annual_returns,
                              s=self.sharpe_ratios * 300, alpha=0.6,
                              c=self.sharpe_ratios, cmap='RdYlGn', edgecolors='black')

        # æ ‡è®°å½“å‰æŠ•èµ„ç»„åˆä½ç½®
        # è®¡ç®—å½“å‰æŠ•èµ„ç»„åˆçš„æ”¶ç›Šç‡å’Œæ³¢åŠ¨ç‡
        weight_array = np.array([weights[s] for s in self.stock_names])
        port_return = np.sum(self.annual_returns * weight_array)
        port_vol = np.sqrt(np.dot(weight_array.T, np.dot(self.cov_matrix, weight_array)))

        # ç”¨çº¢è‰²äº”è§’æ˜Ÿæ ‡è®°å½“å‰ç»„åˆ
        ax2.scatter([port_vol], [port_return], s=300, marker='*',
                    color='red', edgecolors='black', linewidth=2, label='å½“å‰ç»„åˆ')

        # è®¾ç½®å›¾è¡¨å±æ€§
        ax2.set_title('æ”¶ç›Šç‡ vs æ³¢åŠ¨ç‡', fontsize=14, fontweight='bold')
        ax2.set_xlabel('å¹´åŒ–æ³¢åŠ¨ç‡ (%)')
        ax2.set_ylabel('å¹´åŒ–æ”¶ç›Šç‡ (%)')
        ax2.legend()
        ax2.grid(True, alpha=0.3)

        # æ·»åŠ é¢œè‰²æ¡ï¼ˆæ˜¾ç¤ºå¤æ™®æ¯”ç‡é¢œè‰²æ˜ å°„ï¼‰
        cbar2 = plt.colorbar(scatter, ax=ax2)
        cbar2.set_label('å¤æ™®æ¯”ç‡', fontsize=10)
        plt.tight_layout()
        plt.show()

        # ==================== å›¾2: ç›¸å…³æ€§å’Œé£é™©è´¡çŒ® ====================
        # åˆ›å»ºç¬¬äºŒä¸ªå›¾å½¢ï¼ˆ1è¡Œ2åˆ—ï¼‰
        fig2, (ax3, ax4) = plt.subplots(1,2, figsize=(16,6))
        fig2.suptitle('å›¾2: ç›¸å…³æ€§å’Œé£é™©è´¡çŒ®åˆ†æ', fontsize=16, fontweight='bold')

        # 2.1 ç›¸å…³æ€§çƒ­å›¾ï¼ˆå·¦å›¾ï¼‰- åªæ˜¾ç¤ºå‰10åªè‚¡ç¥¨
        top_n = min(10, len(self.stock_names))  # ç¡®å®šæ˜¾ç¤ºæ•°é‡ï¼ˆæœ€å¤š10åªï¼‰
        top_stocks = list(pd.Series(weights).nlargest(top_n).index)     # é€‰å–æƒé‡æœ€å¤§çš„è‚¡ç¥¨
        corr_top = self.corr_matrix.loc[top_stocks, top_stocks]      # è·å–ç›¸å…³æ€§çŸ©é˜µå­é›†

        # ç»˜åˆ¶çƒ­å›¾
        im = ax3.imshow(corr_top.values, cmap='coolwarm', vmin=1, vmax=1)

        # è®¾ç½®å›¾è¡¨å±æ€§
        ax3.set_title(f'å‰{top_n}åªè‚¡ç¥¨ç›¸å…³æ€§çƒ­å›¾', fontsize=14, fontweight='bold')
        ax3.set_xticks(range(len(top_stocks)))
        ax3.set_yticks(range(len(top_stocks)))
        ax3.set_xticklabels(top_stocks, rotation=45, ha='right', fontsize=9)
        ax3.set_yticklabels(top_stocks, fontsize=9)

        # åœ¨çƒ­å›¾å•å…ƒæ ¼ä¸­æ·»åŠ ç›¸å…³ç³»æ•°å€¼
        for i in range(len(top_stocks)):
            for j in range(len(top_stocks)):
                corr_value = corr_top.iloc[i, j]
                ax3.text(j, i, f'{corr_value:.2f}',
                         ha='center', va='center',
                         color='white' if abs(corr_value) > 0.5 else 'black',    # æ ¹æ®èƒŒæ™¯è°ƒæ•´æ–‡å­—é¢œè‰²
                         fontsize=8)
        # æ·»åŠ é¢œè‰²æ¡
        cbar3 = plt.colorbar(im, ax=ax3)
        cbar3.set_label('ç›¸å…³ç³»æ•°', fontsize=10)

        # 2.2 é£é™©è´¡çŒ®é¥¼å›¾ï¼ˆå³å›¾ï¼‰
        # è®¡ç®—é£é™©è´¡çŒ®
        marginal_risk = self.cov_matrix @ weight_array
        total_risk = np.sqrt(np.dot(weight_array.T, np.dot(self.cov_matrix, weight_array)))
        risk_contributions = weight_array * marginal_risk / total_risk
        risk_share = risk_contributions / risk_contributions.sum()

        # è½¬æ¢ä¸ºSerieså¹¶æŒ‰é£é™©è´¡çŒ®æ’åº
        risk_series = pd.Series(risk_share, index=self.stock_names).sort_values(ascending=False)

        # åªæ˜¾ç¤ºä¸»è¦é£é™©è´¡çŒ®è€…ï¼ˆå‰8ä¸ªï¼‰ï¼Œå…¶ä½™åˆå¹¶ä¸º"å…¶ä»–"
        top_risk = risk_series.head(min(8, len(risk_series)))
        if len(risk_series) > 8:
            other_risk = risk_series[8:].sum()
            # åˆ›å»ºSeriesï¼Œè€Œä¸æ˜¯åˆ—è¡¨
            other_series = pd.Series([other_risk], index=['å…¶å®ƒ'])
            top_risk=pd.concat([top_risk, other_series])        # è¿æ¥ä¸¤ä¸ªSeries

        # è®¾ç½®é¥¼å›¾çªå‡ºæ˜¾ç¤ºï¼ˆç¬¬ä¸€ä¸ªæ‰‡åŒºçªå‡º0.1ï¼‰
        explode = [0.1 if i ==0 else 0 for i in range(len(top_risk))]
        # ç”Ÿæˆé¢œè‰²
        colors = plt.cm.Pastel1(np.linspace(0, 1, len(top_risk)))

        # ç»˜åˆ¶é¥¼å›¾
        wedges, texts, autotexts = ax4.pie(top_risk.values, labels=top_risk.index,
                                           autopct='%1.1f%%', startangle=90,
                                           explode=explode, shadow=True,
                                           colors=colors)
        ax4.set_title('é£é™©è´¡çŒ®åˆ†å¸ƒ', fontsize=14, fontweight='bold')

        # ç¾åŒ–é¥¼å›¾æ–‡æœ¬ï¼ˆè®¾ç½®å­—ä½“å’Œé¢œè‰²ï¼‰
        for autotext in autotexts:
            autotext.set_color('black')
            autotext.set_fontweight('bold')
            autotext.set_fontsize(10)
        plt.tight_layout()
        plt.show()

        # ==================== å›¾3: æœ‰æ•ˆå‰æ²¿å’Œç´¯è®¡æ”¶ç›Š ====================
        # åˆ›å»ºç¬¬ä¸‰ä¸ªå›¾å½¢ï¼ˆ1è¡Œ2åˆ—ï¼‰
        fig3, (ax5, ax6) = plt.subplots(1,2, figsize=(16,6))
        fig3.suptitle('å›¾3: æœ‰æ•ˆå‰æ²¿å’Œç´¯è®¡æ”¶ç›Šç‡', fontsize=16, fontweight='bold')

        # 3.1 æœ‰æ•ˆå‰æ²¿å›¾ï¼ˆå·¦å›¾ï¼‰
        # å¦‚æœè¿˜æ²¡æœ‰è®¡ç®—æœ‰æ•ˆå‰æ²¿ï¼Œå…ˆè®¡ç®—
        if self.efficient_frontier is None:
            self.calculate_efficient_frontier()

        # ç»˜åˆ¶æœ‰æ•ˆå‰æ²¿æ›²çº¿
        if self.efficient_frontier is not None and not self.efficient_frontier.empty:
            ax5.plot(self.efficient_frontier['volatility'], self.efficient_frontier['return'],
                     'b-', linewidth=2, alpha=0.7, label='æœ‰æ•ˆå‰æ²¿')
            # æ ‡è®°å…³é”®ç‚¹ï¼šæœ€å°æ³¢åŠ¨ç‡ç»„åˆ
            min_vol_idx = self.efficient_frontier['volatility'].idxmin()
            ax5.scatter(self.efficient_frontier.loc[min_vol_idx, 'volatility'],
                        self.efficient_frontier.loc[min_vol_idx, 'return'],
                        s=200, color='green', marker='o',
                        label='æœ€å°æ³¢åŠ¨ç‡ç»„åˆ', edgecolors='black', linewidth=2)

            # æ ‡è®°å…³é”®ç‚¹ï¼šæœ€å¤§å¤æ™®æ¯”ç‡ç»„åˆ
            max_sharpe_idx = self.efficient_frontier['sharpe'].idxmax()
            ax5.scatter(self.efficient_frontier.loc[max_sharpe_idx, 'volatility'],
                        self.efficient_frontier.loc[max_sharpe_idx, 'return'],
                        s=200, color='gold', marker='s',
                        label='æœ€å¤§å¤æ™®æ¯”ç‡ç»„åˆ', edgecolors='black', linewidth=2)
            # æ ‡è®°å½“å‰ç»„åˆä½ç½®
            ax5.scatter([port_vol], [port_return], s=300, marker='*', color='red',
                        edgecolors='black', linewidth=2, label='å½“å‰ç»„åˆ')
            # è®¾ç½®å›¾è¡¨å±æ€§
            ax5.set_title('æœ‰æ•ˆå‰æ²¿', fontsize=14, fontweight='bold')
            ax5.set_xlabel('æ³¢åŠ¨ç‡ (%)')
            ax5.set_ylabel('æ”¶ç›Šç‡ (%)')
            ax5.legend(loc='best')
            ax5.grid(True, alpha=0.3)

        # 3.2 ç´¯è®¡æ”¶ç›Šç‡æ¯”è¾ƒå›¾ï¼ˆå³å›¾ï¼‰- å¦‚æœæœ‰å›æµ‹æ•°æ®
        if backtest_df is not None:
            # æŠ•èµ„ç»„åˆç´¯è®¡æ”¶ç›Šç‡ï¼šå½’ä¸€åŒ–åˆ°èµ·å§‹ç‚¹1
            port_cumulative = backtest_df['capital'] / backtest_df['capital'].iloc[0]
            ax6.plot(port_cumulative.index, port_cumulative.values, 'b-',
                     linewidth=2, label='æŠ•èµ„ç»„åˆ', alpha=0.8)

            # ç­‰æƒé‡åŸºå‡†ï¼šä½œä¸ºå¯¹æ¯”åŸºå‡†
            equal_weights = {s: 1 / len(self.stock_names) for s in self.stock_names}
            equal_array = np.array([equal_weights[s] for s in self.stock_names])
            equal_returns = (self.stock_returns * equal_array).sum(axis=1)
            equal_cumulative = (1+ equal_returns).cumprod()
            ax6.plot(equal_cumulative.index, equal_cumulative.values, 'r--',
                     linewidth=2, alpha=0.7, label='ç­‰æƒé‡åŸºå‡†')

            # æ— é£é™©åŸºå‡†ï¼šæ˜¾ç¤ºæ— é£é™©æŠ•èµ„çš„è¡¨ç°
            risk_free_cumulative = (1+ self.risk_free_rate) ** np.arange(len(equal_cumulative))
            ax6.plot(equal_cumulative.index, risk_free_cumulative, 'g', linewidth=2,
                     alpha=0.6, label='æ— é£é™©åˆ©ç‡')
            # è®¾ç½®å›¾è¡¨å±æ€§
            ax6.set_title('ç´¯è®¡æ”¶ç›Šç‡å¯¹æ¯”', fontsize=14, fontweight='bold')
            ax6.set_xlabel('æ—¥æœŸ')
            ax6.set_ylabel('ç´¯è®¡æ”¶ç›Šç‡')
            ax6.legend(loc='best')
            ax6.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.show()

        # ==================== å›¾4: å›æ’¤å’Œæœˆåº¦æ”¶ç›Š ====================
        # å¦‚æœæœ‰å›æµ‹æ•°æ®ï¼Œåˆ›å»ºç¬¬å››ä¸ªå›¾å½¢ï¼ˆå›æ’¤åˆ†æå’Œæœˆåº¦æ”¶ç›Šï¼‰
        if backtest_df is not None:
            fig4, (ax7, ax8) = plt.subplots(1,2, figsize=(16,6))
            fig4.suptitle('å›¾4: å›æ’¤åˆ†æå’Œæœˆåº¦æ”¶ç›Š', fontsize=16, fontweight='bold')

            # 4.1 å›æ’¤å›¾ï¼ˆå·¦å›¾ï¼‰
            # è®¡ç®—æ—¥æ”¶ç›Šç‡åºåˆ—
            port_returns = backtest_df['capital'].pct_change().dropna()
            # è®¡ç®—ç´¯è®¡å‡€å€¼
            cumulative = ( 1+ port_returns).cumprod()
            # è®¡ç®—å†å²æœ€é«˜ç‚¹
            running_max = cumulative.expanding().max()
            # è®¡ç®—å›æ’¤ç‡
            drawdown = (cumulative - running_max) / running_max

            # å¡«å……å›æ’¤åŒºåŸŸï¼ˆçº¢è‰²åŒºåŸŸè¡¨ç¤ºäºæŸï¼‰
            ax7.fill_between(drawdown.index, 0, drawdown.values,
                             color='red', alpha=0.3, label='å›æ’¤')
            # ç»˜åˆ¶å›æ’¤æ›²çº¿
            ax7.plot(drawdown.index, drawdown.values, 'r-', linewidth=1, alpha=0.7)
            # æ·»åŠ é›¶çº¿
            ax7.axhline(y=0, color='black', linestyle='-', alpha=0.5)
            # æ ‡è®°æœ€å¤§å›æ’¤ç‚¹
            max_dd = drawdown.min() # æœ€å¤§å›æ’¤å€¼
            max_dd_date = drawdown.idxmin() # æœ€å¤§å›æ’¤å‘ç”Ÿæ—¥æœŸ
            ax7.scatter([max_dd_date], [max_dd], s=100, color='darkred', marker='x',
                        linewidth=2, label=f'æœ€å¤§å›æ’¤: {max_dd:.2%}') # åœ¨å›¾ä¾‹ä¸­æ˜¾ç¤ºå…·ä½“æ•°å€¼
            # è®¾ç½®å›¾è¡¨å±æ€§
            ax7.set_title('å›æ’¤åˆ†æ', fontsize=14, fontweight='bold')
            ax7.set_xlabel('æ—¥æœŸ')
            ax7.set_ylabel('å›æ’¤ (%)')
            ax7.legend(loc='best')
            ax7.grid(True, alpha=0.3)

            # 4.2 æœˆåº¦æ”¶ç›Šç‡çƒ­å›¾ï¼ˆå³å›¾ï¼‰
            # å°†æ—¥æ”¶ç›Šç‡é‡é‡‡æ ·ä¸ºæœˆæ”¶ç›Šç‡
            monthly_returns = port_returns.resample('M').apply(lambda x: (1+x).prod() -1)

            # åˆ›å»ºæœˆåº¦æ”¶ç›ŠçŸ©é˜µï¼ˆå¹´ä»½Ã—æœˆä»½ï¼‰
            monthly_df = pd.DataFrame({
                'year': monthly_returns.index.year,
                'month': monthly_returns.index.month,
                'return': monthly_returns.values
            })

            # å°†æ•°æ®é€è§†æˆå¹´ä»½Ã—æœˆä»½çš„çŸ©é˜µå½¢å¼
            monthly_matrix = monthly_df.pivot(index='year', columns='month', values='return')
            # ç¡®ä¿åŒ…å«æ‰€æœ‰12ä¸ªæœˆä»½
            monthly_matrix = monthly_matrix.reindex(columns=range(1, 13))
            # ç¡®ä¿æ‰€æœ‰æœˆä»½éƒ½æœ‰åˆ—ï¼ˆç”¨NaNå¡«å……ç¼ºå¤±çš„æœˆä»½ï¼‰
            for month in range(1, 13):
                if month not in monthly_matrix.columns:
                    monthly_matrix[month] = np.nan

            # æŒ‰æœˆä»½æ’åº
            monthly_matrix = monthly_matrix[sorted(monthly_matrix.columns)]
            # ç»˜åˆ¶çƒ­å›¾
            im8 = ax8.imshow(monthly_matrix, cmap='RdYlGn', aspect='auto', vmin=-0.2, vmax=0.2)

            # åœ¨çƒ­å›¾å•å…ƒæ ¼ä¸­æ·»åŠ æœˆæ”¶ç›Šç‡æ•°å€¼
            for i in range(monthly_matrix.shape[0]):     # éå†è¡Œï¼ˆå¹´ä»½ï¼‰
                for j in range(monthly_matrix.shape[1]): # éå†åˆ—ï¼ˆæœˆä»½ï¼‰
                    if not pd.isna(monthly_matrix.iloc[i, j]):  # å¦‚æœä¸æ˜¯NaN
                        return_value = monthly_matrix.iloc[i, j]
                        # æ ¹æ®èƒŒæ™¯æ·±æµ…è°ƒæ•´æ–‡å­—é¢œè‰²
                        color= 'white' if abs(return_value) > 0.1 else 'black'
                        ax8.text(j, i, f'{return_value:.1%}',
                                 ha='center', va='center', color=color, fontsize=8, fontweight='bold')

            # è®¾ç½®å›¾è¡¨å±æ€§
            ax8.set_title('æœˆåº¦æ”¶ç›Šç‡çƒ­å›¾', fontsize=14, fontweight='bold')
            ax8.set_xlabel('æœˆä»½')
            ax8.set_ylabel('å¹´ä»½')
            ax8.set_xticks(range(12))
            ax8.set_xticklabels(['1', '2', '3', '4', '5', '6', '7', '8',
                                 '9', '10', '11', '12'], fontsize=9)
            ax8.set_yticks(range(len(monthly_matrix.index)))
            ax8.set_yticklabels(monthly_matrix.index, fontsize=9)

            # æ·»åŠ é¢œè‰²æ¡
            cbar8 = plt.colorbar(im8, ax=ax8)
            cbar8.set_label('æœˆæ”¶ç›Šç‡', fontsize=10)

            # æ˜¾ç¤ºç¬¬å››ä¸ªå›¾å½¢
            plt.tight_layout()
            plt.show()

        # ==================== å›¾5: é£é™©æ”¶ç›Šæ¯” ====================
        # åˆ›å»ºç¬¬äº”ä¸ªå›¾å½¢ï¼ˆå•ç‹¬ä¸€å›¾ï¼‰
        fig5, ax9 = plt.subplots(1, 1, figsize=(16,6))
        fig5.suptitle('å›¾5: å„è‚¡ç¥¨é£é™©æ”¶ç›Šæ¯”åˆ†æ', fontsize=16, fontweight='bold')
        # è®¡ç®—å„è‚¡ç¥¨çš„å¤æ™®æ¯”ç‡ï¼ˆé£é™©æ”¶ç›Šæ¯”ï¼‰å¹¶æ’åº
        risk_reward_ratios = self.sharpe_ratios.sort_values()
        # åˆ›å»ºæ°´å¹³æ¡å½¢å›¾
        y_pos = np.arange(len(risk_reward_ratios))
        bars = ax9.barh(y_pos, risk_reward_ratios.values)

        # æ ¹æ®å¤æ™®æ¯”ç‡æ­£è´Ÿè®¾ç½®é¢œè‰²
        for i, bar in enumerate(bars):
            value = risk_reward_ratios.iloc[i]
            if value >= 0:
                bar.set_color('green')  # æ­£å¤æ™®æ¯”ç‡ç”¨ç»¿è‰²
                bar.set_alpha(0.7)
            else:
                bar.set_color('red')    # è´Ÿå¤æ™®æ¯”ç‡ç”¨çº¢è‰²
                bar.set_alpha(0.7)

            # åœ¨æ¡å½¢æœ«ç«¯æ·»åŠ æ•°å€¼æ ‡ç­¾
            if value >= 0:
                ax9.text(value + 0.01 if value > 0 else 0.01, i,
                         f'{value:.3f}', va='center', fontsize=9, fontweight='bold')
            else:
                ax9.text(value - 0.01, i, f'{value:.3f}', va='center', fontsize=9,
                         fontweight='bold')

        # åœ¨å½“å‰æŠ•èµ„ç»„åˆä¸­çš„è‚¡ç¥¨æ—è¾¹æ·»åŠ æ˜Ÿå·æ ‡è®°
        for i, stock in enumerate(risk_reward_ratios.index):
            if weights.get(stock, 0) > 0.01: # æƒé‡å¤§äº1%çš„è‚¡ç¥¨
                # æ ¹æ®å¤æ™®æ¯”ç‡æ­£è´Ÿå†³å®šæ˜Ÿå·ä½ç½®
                position = -0.2 if risk_reward_ratios[stock] < 0 else -0.1
                ax9.text(position, i, 'â˜…', va='center', fontsize=12, color='gold', fontweight='bold')

        # è®¾ç½®å›¾è¡¨å±æ€§
        ax9.set_yticks(y_pos)
        ax9.set_yticklabels(risk_reward_ratios.index, fontsize=10)
        ax9.set_xlabel('å¤æ™®æ¯”ç‡', fontsize=12)
        ax9.set_title('å„è‚¡ç¥¨é£é™©æ”¶ç›Šæ¯” (â˜… è¡¨ç¤ºåœ¨æŠ•èµ„ç»„åˆä¸­çš„è‚¡ç¥¨)',
                      fontsize=14, fontweight='bold')
        # æ·»åŠ é›¶çº¿
        ax9.axvline(x=0, color='black', linestyle='-', alpha=0.5, linewidth=1)
        ax9.grid(True, alpha=0.3, axis='x')      # ä»…xè½´æ·»åŠ ç½‘æ ¼
        # æ·»åŠ è‡ªå®šä¹‰å›¾ä¾‹
        from matplotlib.patches import Patch
        legend_elements = [
            Patch(facecolor='green', alpha=0.7, label='æ­£å¤æ™®æ¯”ç‡'),
            Patch(facecolor='red', alpha=0.7, label='è´Ÿå¤æ™®æ¯”ç‡'),
            Patch(facecolor='white', label='â˜… è¡¨ç¤ºåœ¨æŠ•èµ„ç»„åˆä¸­')
        ]
        ax9.legend(handles=legend_elements, loc='lower right')

        plt.tight_layout()
        plt.show()
        # æ‰“å°å®Œæˆä¿¡æ¯
        print("âœ… 5å¼ åˆ†æå›¾è¡¨ç”Ÿæˆå®Œæˆï¼")

    def run_complete_analysis(self, weights, benchmark_weights=None):
        """
                è¿è¡Œå®Œæ•´çš„åˆ†ææµç¨‹

                å‚æ•°:
                weights: æŠ•èµ„ç»„åˆæƒé‡
                benchmark_weights: åŸºå‡†ç»„åˆæƒé‡
                """
        # 1. æ‰“å°å®Œæ•´åˆ†æå¼€å§‹ä¿¡æ¯
        print(f"\n{'=' * 80}")
        print("ğŸš€ å¼€å§‹å®Œæ•´æŠ•èµ„ç»„åˆåˆ†æ")
        print("=" * 80)

        # 2. ç¬¬ä¸€æ­¥ï¼šæŠ•èµ„ç»„åˆä¼˜åŒ–
        print("\nğŸ“‹ ç¬¬1æ­¥: æŠ•èµ„ç»„åˆä¼˜åŒ–")
        # 2.1 æ‰§è¡Œæœ€å¤§åŒ–å¤æ™®æ¯”ç‡ä¼˜åŒ–ï¼ˆå¸¦çº¦æŸï¼šå•åªè‚¡ç¥¨æœ€å¤š20%ï¼Œæœ€å°‘1%ï¼‰
        self.optimize_portfolio(optimization_type='max_sharpe',
                                constraints={'max_weight': 0.2, 'min_weight':0.01})

        # 3. ç¬¬äºŒæ­¥ï¼šæœ‰æ•ˆå‰æ²¿è®¡ç®—
        print("\nğŸ“‹ ç¬¬2æ­¥: æœ‰æ•ˆå‰æ²¿è®¡ç®—")
        # 3.1 è®¡ç®—æœ‰æ•ˆå‰æ²¿ï¼ˆé»˜è®¤20ä¸ªç‚¹ï¼‰
        self.calculate_efficient_frontier()

        # 4. ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆå®Œæ•´æŠ¥å‘Š
        print("\nğŸ“‹ ç¬¬3æ­¥: ç”Ÿæˆå®Œæ•´æŠ¥å‘Š")
        # 4.1 è°ƒç”¨ä¹‹å‰å®šä¹‰çš„generate_comprehensive_reportæ–¹æ³•ç”ŸæˆæŠ¥å‘Š
        report = self.generate_comprehensive_report(weights, benchmark_weights)

        # 5. ç¬¬å››æ­¥ï¼šè·å–å›æµ‹æ•°æ®
        print("\nğŸ“‹ ç¬¬4æ­¥: è·å–å›æµ‹æ•°æ®")
        # 5.1 æ‰§è¡Œå›æµ‹åˆ†æï¼ˆé»˜è®¤åˆå§‹èµ„æœ¬10000ï¼Œå­£åº¦å†å¹³è¡¡ï¼‰
        backtest_df, backtest_metrics = self.backtest_portfolio(weights)

        # 6. ç¬¬äº”æ­¥ï¼šç”Ÿæˆåˆ†æå›¾è¡¨
        print("\nğŸ“‹ ç¬¬5æ­¥: ç”Ÿæˆåˆ†æå›¾è¡¨")
        # 6.1 è°ƒç”¨ä¹‹å‰å®šä¹‰çš„plot_comprehensive_analysisæ–¹æ³•ç”Ÿæˆ5å¼ å›¾è¡¨
        self.plot_comprehensive_analysis(weights, backtest_df)

        # 7. æ‰“å°åˆ†ææ€»ç»“
        print(f"\n{'=' * 80}")
        print("ğŸ‰ å®Œæ•´æŠ•èµ„ç»„åˆåˆ†æå®Œæˆï¼")
        print("=" * 80)
        # 8. è¿”å›æ‰€æœ‰åˆ†æç»“æœ
        return report

def load_real_stock_data(stock_list, start_date='2019-01-01', end_date='2025-12-02'):
    """
    ä»Excelæ–‡ä»¶åŠ è½½çœŸå®çš„è‚¡ç¥¨æ•°æ®
    å‚æ•°:
        stock_list -- è‚¡ç¥¨ä»£ç åˆ—è¡¨
        start_date -- å¼€å§‹æ—¥æœŸï¼ˆé»˜è®¤ä¸º2019å¹´ï¼Œä½¿ç”¨æœ€è¿‘æ•°æ®ï¼‰
        end_date -- ç»“æŸæ—¥æœŸï¼ˆé»˜è®¤ä¸º2025å¹´12æœˆ2æ—¥ï¼‰
    åŠŸèƒ½è¯´æ˜:
        - é€ä¸ªåŠ è½½æ¯ä¸ªè‚¡ç¥¨çš„Excelæ•°æ®æ–‡ä»¶
        - è‡ªåŠ¨è¯†åˆ«æ—¥æœŸåˆ—å’Œä»·æ ¼åˆ—
        - è®¡ç®—æ—¥æ”¶ç›Šç‡
        - å¯¹é½æ‰€æœ‰è‚¡ç¥¨çš„æ•°æ®æ—¥æœŸ
        - è¿”å›æ¸…ç†åçš„æ”¶ç›Šç‡DataFrame
    æ•°æ®å¤„ç†æµç¨‹:
        1. è¯»å–Excelæ–‡ä»¶
        2. è¯†åˆ«æ—¥æœŸåˆ—ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
        3. è®¾ç½®æ—¥æœŸç´¢å¼•
        4. è¯†åˆ«ä»·æ ¼åˆ—ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
        5. è®¡ç®—æ”¶ç›Šç‡
        6. æ•°æ®è´¨é‡æ£€æŸ¥
    ä¸ºä»€ä¹ˆé€‰æ‹©2019-2025å¹´æ•°æ®:
        1. æœ€è¿‘æ•°æ®æ›´èƒ½åæ˜ å½“å‰å¸‚åœºç‰¹å¾
        2. é¿å…è¿‡æ—¶çš„å¸‚åœºç»“æ„å½±å“åˆ†æ
        3. è¶³å¤Ÿçš„æ•°æ®é‡è¿›è¡Œå¯é åˆ†æï¼ˆ6-7å¹´ï¼‰
        """
    print("ğŸ“Š ä»Excelæ–‡ä»¶åŠ è½½çœŸå®è‚¡ç¥¨æ•°æ®...")
    print(f"æ•°æ®æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")

    all_returns = {}
    all_prices = {}
    loaded_stocks = []
    for stock in stock_list:
        try:
            file_path = f"./{stock}_stock_data.xlsx"
            if not os.path.exists(file_path):
                print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                continue
            df = pd.read_excel(file_path)
            print(f"\nğŸ“ˆ å¤„ç† {stock} æ•°æ®:")
            print(f"  æ–‡ä»¶åˆ—å: {list(df.columns)}")
            print(f"  æ•°æ®è¡Œæ•°: {len(df)}")

            # æ£€æŸ¥æ•°æ®æ—¶é—´èŒƒå›´
            # å°è¯•ä¸åŒçš„æ—¥æœŸåˆ—å
            date_columns = ['date', 'Date', 'DATE', 'datetime', 'Datetime', 'æ—¥æœŸ', 'æ—¶é—´']
            date_col = None
            for col in date_columns:
                if col in df.columns:
                    date_col = col
                    print(f"  æ‰¾åˆ°æ—¥æœŸåˆ—: {date_col}")
                    break

            if date_col is None:
                # å°è¯•ç¬¬ä¸€åˆ—æ˜¯å¦æ˜¯æ—¥æœŸç±»å‹
                first_col = df.columns[0]
                print(f"  å°è¯•ç¬¬ä¸€åˆ—ä½œä¸ºæ—¥æœŸ: {first_col}")

                # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
                try:
                    df[first_col] = pd.to_datetime(df[first_col], errors='coerce')
                    if df[first_col].isnull().all():
                        raise ValueError("æ— æ³•è½¬æ¢ä¸ºæ—¥æœŸ")
                    date_col = first_col
                    print(f"  æˆåŠŸè½¬æ¢ç¬¬ä¸€åˆ—ä¸ºæ—¥æœŸ")
                except:
                    # å°è¯•å…¶ä»–å¯èƒ½çš„æ—¥æœŸåˆ—
                    for col in df.columns:
                        if 'date' in str(col).lower() or 'time' in str(col).lower():
                            try:
                                df[col] = pd.to_datetime(df[col], errors='coerce')
                                date_col = col
                                print(f"  æ‰¾åˆ°æ—¥æœŸåˆ—: {col}")
                                break
                            except:
                                continue
            if date_col is None:
                raise ValueError(f"æœªæ‰¾åˆ°æ—¥æœŸåˆ—ï¼Œå¯ç”¨åˆ—: {list(df.columns)}")
            # è®¾ç½®æ—¥æœŸç´¢å¼•
            df[date_col] = pd.to_datetime(df[date_col])
            df.set_index(date_col, inplace=True)

            df = df.sort_index()
            # æ˜¾ç¤ºæ•°æ®æ—¶é—´èŒƒå›´
            if len(df) > 0:
                print(f"  åŸå§‹æ•°æ®æ—¶é—´èŒƒå›´: {df.index[0].date()} åˆ° {df.index[-1].date()}")
            # å°è¯•ä¸åŒçš„ä»·æ ¼åˆ—å
            price_columns = ['close', 'Close', 'Adj Close', 'Price', 'price',
                             'Close_Price', 'close_price', 'Adj Close_Price',
                             'æ”¶ç›˜ä»·', 'æ”¶ç›˜', 'ClosePrice']
            price_col = None
            for col in price_columns:
                if col in df.columns:
                    price_col = col
                    print(f"  æ‰¾åˆ°ä»·æ ¼åˆ—: {price_col}")
                    break

            if price_col is None:
                for col in df.columns:
                    col_lower = str(col).lower()
                    if 'price' in col_lower or 'close' in col_lower or 'adj' in col_lower:
                        price_col = col
                        print(f"  ä½¿ç”¨å¯èƒ½çš„ä»·æ ¼åˆ—: {price_col}")
                        break
            if price_col is None and len(df.columns) >=2:
                # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œå°è¯•æ•°å€¼åˆ—
                for col in df.columns:
                    if col != date_col and pd.api.types.is_numeric_dtype(df[col]):
                        price_col = col
                        print(f"  ä½¿ç”¨æ•°å€¼åˆ—ä½œä¸ºä»·æ ¼: {price_col}")
                        break
            if price_col is None:
                raise ValueError(f"æœªæ‰¾åˆ°ä»·æ ¼åˆ—ï¼Œå¯ç”¨åˆ—: {list(df.columns)}")

            # è·å–ä»·æ ¼åºåˆ—
            prices = df[price_col]

            # æ£€æŸ¥ä»·æ ¼æ•°æ®
            print(f"  ä»·æ ¼æ•°æ®ç»Ÿè®¡:")
            print(f"    éç©ºå€¼æ•°é‡: {prices.count()}")
            print(f"    ç¼ºå¤±å€¼æ•°é‡: {prices.isnull().sum()}")
            print(f"    ä»·æ ¼èŒƒå›´: {prices.min():.2f} - {prices.max():.2f}")

            prices = prices.dropna()
            if len(prices) == 0:
                print(f"  âš ï¸  {stock}: ä»·æ ¼æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡")
                continue

            # æ˜¾ç¤ºæ•°æ®æˆªæ­¢æ—¥æœŸ
            latest_date = prices.index[-1]
            print(f"  æœ€æ–°æ•°æ®æ—¥æœŸ: {latest_date.date()}")

            # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®
            min_required_date = pd.Timestamp('2019-01-01')
            if prices.index[0] > min_required_date:
                print(f"  âš ï¸  {stock}: å†å²æ•°æ®ä¸è¶³ï¼Œæœ€æ—©æ•°æ®ä» {prices.index[0].date()} å¼€å§‹")

            # ä½¿ç”¨å®Œæ•´æ•°æ®èŒƒå›´ï¼ˆä¸è¿›è¡Œé¢å¤–è¿‡æ»¤ï¼‰
            print(f"  ä½¿ç”¨æ•°æ®èŒƒå›´: {prices.index[0].date()} åˆ° {prices.index[-1].date()}")

            # è®¡ç®—æ—¥æ”¶ç›Šç‡
            returns = prices.pct_change().dropna()

            # æ£€æŸ¥æ”¶ç›Šç‡æ•°æ®æœ‰æ•ˆæ€§
            print(f"  æ”¶ç›Šç‡æ•°æ®ç»Ÿè®¡:")
            print(f"    æœ‰æ•ˆæ”¶ç›Šç‡æ•°é‡: {len(returns)}")
            print(f"    å¹³å‡æ—¥æ”¶ç›Šç‡: {returns.mean():.4%}")
            print(f"    æ—¥æ”¶ç›Šç‡æ³¢åŠ¨ç‡: {returns.std():.4%}")

            if len(returns) < 100:
                print(f"  âš ï¸  {stock}: æœ‰æ•ˆæ”¶ç›Šç‡æ•°æ®ä¸è¶³ ({len(returns)}å¤©)ï¼Œè·³è¿‡")
                continue

            all_returns[stock] = returns
            all_prices[stock] = prices
            loaded_stocks.append(stock)

            print(f"  âœ… {stock}: æˆåŠŸåŠ è½½{len(prices)}å¤©ä»·æ ¼æ•°æ®ï¼Œ{len(returns)}å¤©æ”¶ç›Šç‡æ•°æ®")
            print(f"     æ—¶é—´èŒƒå›´: {prices.index[0].date()} åˆ° {prices.index[-1].date()}")
        except Exception as e:
            print(f"  âŒ {stock}: åŠ è½½å¤±è´¥ - {str(e)[:100]}...")
            continue

    if not all_returns:
        raise ValueError("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•è‚¡ç¥¨æ•°æ®")

    # åˆ›å»ºæ”¶ç›Šç‡DataFrame
    returns_df = pd.DataFrame(all_returns)
    print(f"\nâœ… æˆåŠŸåŠ è½½ {len(all_returns)} åªè‚¡ç¥¨æ•°æ®: {', '.join(loaded_stocks)}")
    print(f"   æœ€ç»ˆæ•°æ®æ—¶é—´èŒƒå›´: {returns_df.index[0].date()} åˆ° {returns_df.index[-1].date()}")
    print(f"   äº¤æ˜“æ—¥æ•°: {len(returns_df)}")

    # æ˜¾ç¤ºå„è‚¡ç¥¨æ•°æ®é‡
    print(f"\nğŸ“Š å„è‚¡ç¥¨æ•°æ®é‡ç»Ÿè®¡:")
    for stock in loaded_stocks:
        if stock in returns_df.columns:
            data_count = returns_df[stock].count()
            if data_count > 0:
                date_range = f"{returns_df[stock].dropna().index[0].date()} åˆ°{returns_df[stock].dropna().index[-1].date()}"
                print(f"  {stock}: {data_count}ä¸ªäº¤æ˜“æ—¥ï¼Œ{date_range}")
    return returns_df, all_prices, loaded_stocks

# ==================== ä¸»å‡½æ•° ====================
def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºå®Œæ•´åˆ†æç³»ç»Ÿ"""
    print("ğŸ“Š åŸºäºæ‚¨çš„çœŸå®æŒä»“è¿›è¡ŒæŠ•èµ„ç»„åˆåˆ†æ")
    print("=" * 60)

    # 1. å®šä¹‰æ‚¨çš„è‚¡ç¥¨æŒä»“ï¼ˆæ ¹æ®æ‚¨æä¾›çš„ä¿¡æ¯ï¼‰
    stock_holdings = {
        'SCHD': 156,  # Schwabç¾å›½è‚¡æ¯ETF
        'KO': 155,  # å¯å£å¯ä¹
        'VOO': 155,  # Vanguardæ ‡æ™®500 ETF
        'GLD': 107,  # é»„é‡‘ETF
        'LLY': 103,  # ç¤¼æ¥å…¬å¸
        'AAPL': 64,  # è‹¹æœå…¬å¸
        'TSLA': 49,  # ç‰¹æ–¯æ‹‰
        'AA': 49,  # ç¾å›½é“ä¸š
        'AMZN': 48,  # äºšé©¬é€Š
        'UPST': 43,  # Upstart Holdings
        'UNH': 42,  # è”åˆå¥åº·
        'GOOGL': 41,  # è°·æ­Œ
        'SBUX': 39,  # æ˜Ÿå·´å…‹
        'OMI': 32,  # Owens & Minor
        'RKLB': 22,  # Rocket Lab
        'ASTS': 22  # AST SpaceMobile
    }

    # 2. è®¡ç®—æ€»æŠ•èµ„é‡‘é¢å’Œæƒé‡
    total_value = sum(stock_holdings.values())
    portfolio_weights = {}
    print("\nğŸ“Š æ‚¨çš„æŒä»“è¯¦æƒ…:")
    print("-" * 50)
    print(f"{'è‚¡ç¥¨':<8} {'æŒä»“é‡‘é¢($)':<12} {'æƒé‡':<10}")
    print("-" * 50)

    for stock, value in stock_holdings.items():
        weight = value / total_value
        portfolio_weights[stock] = weight
        print(f"{stock:<8} ${value:<11} {weight:.2%}")
    print("-" * 50)
    print(f"{'æ€»è®¡':<8} ${total_value:<11} {sum(portfolio_weights.values()):.2%}")

    # 3. åŠ è½½çœŸå®è‚¡ç¥¨æ•°æ®
    print(f"\nğŸ”„ æ­£åœ¨åŠ è½½è‚¡ç¥¨æ•°æ®...")

    try:
        # è°ƒç”¨æ‚¨çš„æ•°æ®åŠ è½½å‡½æ•°
        stock_list = list(stock_holdings.keys())
        returns_df, all_prices, loaded_stocks = load_real_stock_data(
            stock_list=stock_list,
            start_date = '2020-01-01',
            end_date = '2025-12-12'
        )
        # 4. æ£€æŸ¥å“ªäº›è‚¡ç¥¨æˆåŠŸåŠ è½½
        print(f"\nâœ… æ•°æ®åŠ è½½å®Œæˆ:")
        print(f"   æˆåŠŸåŠ è½½è‚¡ç¥¨: {len(loaded_stocks)}/{len(stock_list)}åª")

        # 5. æ£€æŸ¥æ˜¯å¦æœ‰è‚¡ç¥¨æ•°æ®ç¼ºå¤±
        missing_stocks = set(stock_list) - set(loaded_stocks)
        if missing_stocks:
            print(f"   âš ï¸ ä»¥ä¸‹è‚¡ç¥¨æ•°æ®ç¼ºå¤±: {', '.join(missing_stocks)}")
            print("   æ³¨æ„: ç¼ºå¤±è‚¡ç¥¨å°†ä»åˆ†æä¸­æ’é™¤")
            # æ›´æ–°æƒé‡ï¼Œæ’é™¤ç¼ºå¤±çš„è‚¡ç¥¨
            remaining_value = sum([stock_holdings[s] for s in loaded_stocks])
            for stock in missing_stocks:
                if stock in portfolio_weights:
                    del portfolio_weights[stock]

            # é‡æ–°è®¡ç®—æƒé‡
            for stock in loaded_stocks:
                portfolio_weights[stock] = stock_holdings[stock] / remaining_value

        print(f"\nğŸ“Š å°†åˆ†æçš„æŠ•èµ„ç»„åˆ:")
        for stock in loaded_stocks:
            weight = portfolio_weights.get(stock, 0)
            value = stock_holdings[stock]
            print(f"   {stock}: ${value} ({weight:.2%})")

        # 6. æ˜¾ç¤ºæ•°æ®åŸºæœ¬ä¿¡æ¯
        print(f"\nğŸ“ˆ æ•°æ®åŸºæœ¬ä¿¡æ¯:")
        print(f"   æ•°æ®æœŸé—´: {returns_df.index[0].date()} åˆ° {returns_df.index[-1].date()}")
        print(f"   æœ‰æ•ˆäº¤æ˜“æ—¥æ•°: {len(returns_df)}")

        # 7. åˆ›å»ºåˆ†æå™¨å¯¹è±¡
        print(f"\nğŸ”„ åˆ›å»ºæŠ•èµ„ç»„åˆåˆ†æå™¨...")
        analyzer = CompletePortfolioAnalyzer(returns_df, risk_free_rate=0.03)

        # 8. è¿è¡Œå®Œæ•´åˆ†æ
        print(f"\n{'=' * 80}")
        print("ğŸš€ å¼€å§‹åŸºäºæ‚¨æŒä»“çš„å®Œæ•´æŠ•èµ„ç»„åˆåˆ†æ")
        print("=" * 80)
        report = analyzer.run_complete_analysis(portfolio_weights)

        # 9. æ‰“å°åˆ†ææ€»ç»“
        print(f"\nğŸ“Š æ‚¨çš„æŠ•èµ„ç»„åˆåˆ†ææ€»ç»“:")
        print("-" * 60)
        print(f"   æ€»æŠ•èµ„é‡‘é¢: ${total_value:,.2f}")
        print(f"   åˆ†æè‚¡ç¥¨æ•°é‡: {len(loaded_stocks)}åª")
        print(f"   æŠ•èµ„ç»„åˆå¤æ™®æ¯”ç‡: {report['portfolio_metrics']['å¤æ™®æ¯”ç‡']:.3f}")
        print(f"   æŠ•èµ„ç»„åˆå¹´åŒ–æ”¶ç›Šç‡: {report['portfolio_metrics']['å¹´åŒ–æ”¶ç›Šç‡']:.2%}")
        print(f"   æŠ•èµ„ç»„åˆå¹´åŒ–æ³¢åŠ¨ç‡: {report['portfolio_metrics']['å¹´åŒ–æ³¢åŠ¨ç‡']:.2%}")
        print(f"   æœ€å¤§å›æ’¤: {report['backtest_metrics']['æœ€å¤§å›æ’¤']:.2%}")
        print(f"   æœ€ç»ˆèµ„æœ¬æ¨¡æ‹Ÿ: ${report['backtest_metrics']['æœ€ç»ˆèµ„æœ¬']:,.2f}")
        print(f"   å†å¹³è¡¡æ¬¡æ•°: {report['backtest_metrics']['å†å¹³è¡¡æ¬¡æ•°']}")
        print("-" * 60)

        # 10. æ˜¾ç¤ºå„è‚¡ç¥¨è¡¨ç°
        print(f"\nğŸ† å„è‚¡ç¥¨å†å²è¡¨ç°:")
        print("-" * 70)
        print(f"{'è‚¡ç¥¨':<8} {'æƒé‡':<8} {'å¹´åŒ–æ”¶ç›Šç‡':<12} {'å¹´åŒ–æ³¢åŠ¨ç‡':<12} {'å¤æ™®æ¯”ç‡':<10}")
        print("-" * 70)

        for stock in loaded_stocks:
            weight = portfolio_weights.get(stock, 0)
            return_val = analyzer.annual_returns[stock]
            vol_val = analyzer.annual_volatility[stock]
            sharpe_val = analyzer.sharpe_ratios[stock]
            print(f"{stock:<8} {weight:<8.2%} {return_val:<12.2%} {vol_val:<12.2%} {sharpe_val:<10.3f}")

        # 11. æä¾›é’ˆå¯¹æ€§çš„æŠ•èµ„å»ºè®®
        print(f"\nğŸ’¡ é’ˆå¯¹æ‚¨æŒä»“çš„æŠ•èµ„å»ºè®®:")

        # è·å–é£é™©åˆ†æç»“æœ
        risk_df = report['risk_analysis']

        # è¯†åˆ«é«˜é£é™©è‚¡ç¥¨ï¼ˆé£é™©å€æ•° > 1.5ï¼‰
        high_risk = risk_df[risk_df['é£é™©å€æ•°']> 1.5]
        if len(high_risk) > 0:
            print(f"\nâš ï¸  é«˜é£é™©è­¦æŠ¥ - å»ºè®®è€ƒè™‘å‡ä»“:")
            for _, row in high_risk.iterrows():
                stock = row['è‚¡ç¥¨']
                current_weight = row['æƒé‡']
                risk_multiplier = row['é£é™©å€æ•°']
                current_value = stock_holdings.get(stock, 0)

                # å»ºè®®å‡å°‘åˆ°é£é™©å€æ•°=1
                suggested_weight = current_weight / risk_multiplier
                suggested_value = suggested_weight * total_value
                reduction = current_value - suggested_value
                print(f"   {stock}: å½“å‰${current_value} ({current_weight:.1%}) â†’ "
                      f"å»ºè®®${suggested_value:,.0f} ({suggested_weight:.1%}) "
                      f"å‡å°‘${reduction:,.0f}")

        # è¯†åˆ«ä½é£é™©è‚¡ç¥¨ï¼ˆé£é™©å€æ•° < 0.7ï¼‰
        low_risk = risk_df[risk_df['é£é™©å€æ•°'] < 0.7]
        if len(low_risk) > 0:
            print(f"\nâœ… ä½é£é™©æœºä¼š - å¯ä»¥è€ƒè™‘åŠ ä»“:")
            for _, row in low_risk.iterrows():
                stock = row['è‚¡ç¥¨']
                current_weight = row['æƒé‡']
                risk_multiplier = row['é£é™©å€æ•°']
                current_value = stock_holdings.get(stock, 0)
                # å»ºè®®å¢åŠ 50%
                suggested_weight = current_weight * 1.5
                suggested_value = suggested_weight * total_value
                increase = suggested_value - current_value
                print(f"   {stock}: å½“å‰${current_value} ({current_weight:.1%}) â†’ "
                      f"å»ºè®®${suggested_value:,.0f} ({suggested_weight:.1%}) "
                      f"å¢åŠ ${increase:,.0f}")

        # 12. è¿”å›åˆ†æç»“æœ
        print(f"\nâœ… åˆ†æå®Œæˆï¼")
        print("ğŸ’¡ è¯·æŸ¥çœ‹ç”Ÿæˆçš„5å¼ å›¾è¡¨è·å–å¯è§†åŒ–åˆ†æ")
        return report
    except Exception as e:
        print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        print("è¯·æ£€æŸ¥:")
        print("1. Excelæ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®")
        print("2. è‚¡ç¥¨ä»£ç æ˜¯å¦æ­£ç¡®ï¼ˆæ³¨æ„å¤§å°å†™ï¼‰")
        print("3. æ•°æ®æ–‡ä»¶å‘½åæ ¼å¼: {è‚¡ç¥¨ä»£ç }_stock_data.xlsx")
        print("4. Excelæ–‡ä»¶ä¸­åŒ…å«æ­£ç¡®çš„æ—¥æœŸå’Œä»·æ ¼æ•°æ®")
        import traceback
        traceback.print_exc()
        return None

# ==================== ç¨‹åºå…¥å£ç‚¹ ====================
if __name__ == "__main__":
    # è¿è¡Œåˆ†æ
    report = main()

    if report:
        print("\nğŸ™ æ„Ÿè°¢ä½¿ç”¨æŠ•èµ„ç»„åˆåˆ†æç³»ç»Ÿï¼")
        print("ğŸ“Š æç¤º: è¯·æŸ¥çœ‹ç”Ÿæˆçš„5å¼ å›¾è¡¨è·å–å¯è§†åŒ–åˆ†æ")
    else:
        print("\nâŒ åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»¥ä¸Šé”™è¯¯ä¿¡æ¯")










