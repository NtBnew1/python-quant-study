'''
Day 7ï¼šæŠ•èµ„ç»„åˆä¼˜åŒ–
ç›®æ ‡ï¼š
-ç»“åˆQuantLibå’Œä¼˜åŒ–å·¥å…·ï¼ˆcvxpy/ PyPortfolioOptï¼‰ã€‚
-æ„å»ºæœ€ä¼˜æŠ•èµ„ç»„åˆã€‚
ä»»åŠ¡ï¼š
-å¯¼å…¥å†å²æ”¶ç›Šç‡æ•°æ®ã€‚
-è®¡ç®—æœŸæœ›æ”¶ç›Šã€åæ–¹å·®çŸ©é˜µã€‚
-æ±‚è§£æœ€ä¼˜æƒé‡ç»„åˆï¼ˆæœ€å°æ–¹å·®æˆ–æœ€å¤§å¤æ™®æ¯”ç‡ï¼‰ã€‚
è¾“å‡ºï¼šç»„åˆä¼˜åŒ–è„šæœ¬ã€‚
'''

# å¯¼å…¥åº“
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import scipy.optimize as sco
import QuantLib as ql
import os
from datetime import datetime, timedelta



# è®¾ç½®ä¸­æ–‡å­—ä½“,
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

class SmartPortfolioOptimizer:
    '''
    æ™ºèƒ½æŠ•èµ„ç»„åˆä¼˜åŒ–å™¨ç±»
    ä¸»è¦: è‡ªåŠ¨é€‰è‚¡ç¥¨, è®¡ç®—æ”¶ç›Šç‡, ä¼˜åŒ–æƒé‡, é£é™©åˆ†æ, å¯è§†åŒ–ç»“æœ
    '''
    def __init__(self, max_stocks=15):
        '''
        åˆå§‹åŒ–ä¼˜åŒ–å™¨
        å‚æ•°: max_stocks: æœ€å¤§é€‰æ‹©è‚¡ç¥¨çš„æ•°é‡, é¿å…è¿‡å¤šè‚¡ç¥¨å¯¼è‡´ä¼˜åŒ–å¤æ‚
        '''
        self.risk_free_rate = 0.02  # æ— é£é™©åˆ©ç‡, é»˜è®¤2%
        self.max_stocks = max_stocks

    def load_all_stock_data(self):
        '''
        åŠ è½½æ‰€æœ‰å¯ç”¨çš„è‚¡ç¥¨æ•°æ®
        åŠŸèƒ½: æ‰«æå½“å‰ç›®å½•, è¯»å–æ‰€æœ‰è‚¡ç¥¨æ•°æ®Excelæ–‡ä»¶
        è¿”å›: åŒ…å«æ‰€æœ‰è‚¡ç¥¨æ•°æ®çš„å­—å…¸
        '''
        print(f"...æ‰«æå¹¶åŠ è½½æ‰€æœ‰è‚¡ç¥¨æ•°æ®...")
        # ä½¿ç”¨åˆ—è¡¨æ¨åˆ°å¼æ‰¾åˆ°æ‰€æœ‰çš„ä»¥'_stock.xlsx' ç»“å°¾çš„æ–‡ä»¶
        stock_files = [f for f in os.listdir('.') if f.endswith('_stock.xlsx')]

        # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°è‚¡ç¥¨æ–‡ä»¶
        if not stock_files:
            print(f" æœªæ‰¾åˆ°ä»»ä½•è‚¡ç¥¨æ•°æ®æ–‡ä»¶ (*_stock.xlsx)")
            return None

        stock_data = {} # ç”¨äºå­˜å‚¨æ‰€æœ‰è‚¡ç¥¨æ•°æ®

        # éå†æ¯ä¸ªè‚¡ç¥¨æ–‡ä»¶å¹¶åŠ è½½æ•°æ®
        for file in sorted(stock_files):    # sorted ç¡®ä¿æŒ‰å­—æ¯é¡ºåºå¤„ç†
            try:
                # ä»æ–‡ä»¶åæå–è‚¡ç¥¨ä»£ç : AAPL_stock.xlsx -->AAPL
                stock_code = file.replace('_stock.xlsx', '')
                # è¯»å–excelæ–‡ä»¶, index_col=0è¡¨ç¤ºç¬¬ä¸€åˆ—ä½œä¸ºç´¢å¼• (é€šå¸¸æ˜¯æ—¥æœŸ)
                df = pd.read_excel(file, index_col=0)
                # éªŒè¯æ•°æ®æ ¼å¼, å¿…é¡»æœ‰Closeåˆ—ä¸”æ•°æ®ä¸ä¸ºç©º
                if 'Close' in df.columns and not df.empty:
                    stock_data[stock_code] = df # å­˜å‚¨åˆ°å­—å…¸ä¸­
                    print(f"åŠ è½½{stock_code}: {len(df)}ä¸ªäº¤æ˜“æ—¥æ•°æ®")
            except Exception as e:
                print(f"åŠ è½½{file} å¤±è´¥:{e}")
        print(f"\n æˆåŠŸåŠ è½½ {len(stock_data)}åªè‚¡ç¥¨")
        return stock_data

    def filter_stocks_by_performance(self, stock_data, min_trading_days = 1000):
        '''
        æ ¹æ®è‚¡ç¥¨è¡¨ç°ç­›é€‰ä¼˜è´¨è‚¡ç¥¨
        åŠŸèƒ½: è®¡ç®—æ¯åªè‚¡ç¥¨çš„å¤æ™®æ¯”ç‡, é€‰æ‹©è¡¨ç°æœ€å¥½çš„å‰Nåª
        å‚æ•°: stock_data: æ‰€æœ‰è‚¡ç¥¨æ•°æ®
            min_trading_days: æœ€å°äº¤æ˜“å¤©æ•°è¦æ±‚, ç¡®ä¿æ•°æ®å……è¶³
        è¿”å›: ç­›é€‰åçš„è‚¡ç¥¨æ•°æ®
        '''
        print(f"\n ç­›é€‰è‚¡ç¥¨ (æœ€å°‘{min_trading_days}ä¸ªäº¤æ˜“æ—¥)")

        filtered_stocks = {}    # å­˜å‚¨ç­›é€‰åçš„è‚¡ç¥¨æ•°æ®
        performance_stats = {}  # å­˜å‚¨æ¯åªè‚¡ç¥¨çš„æ€§èƒ½æŒ‡æ ‡
        # éå†æ¯åªè‚¡ç¥¨, è®¡ç®—å…³é”®æ€§èƒ½æŒ‡æ ‡
        for ticker, df in stock_data.items():
            # é¦–å…ˆæ£€æŸ¥äº¤æ˜“å¤©æ•°æ˜¯å¦æ»¡è¶³è¦æ±‚
            if len(df) < min_trading_days:
                continue    # è·³è¿‡ä¸æ»¡è¶³å¤©æ•°è¦æ±‚çš„æ•°æ®
            try:
                # è®¡ç®—æ—¥æ”¶ç›Šç‡: ä»Šæ—¥æ”¶ç›˜ä»·/æ˜¨æ—¥æ”¶ç›˜ä»· - 1
                returns = df['Close'].pct_change().dropna()
                # å†æ¬¡æ£€æŸ¥æ”¶ç›Šç‡æ•°æ®çš„é•¿åº¦
                if len(returns) < min_trading_days:
                    continue

                # è®¡ç®—å…³é”®é‡‘èæŒ‡æ ‡
                daily_return = returns.mean()           # æ—¥å‡æ”¶ç›Šç‡
                daily_vol = returns.std()               # æ—¥æ³¢åŠ¨ç‡ (æ ‡å‡†å·®)
                annual_return = daily_return * 252      # å¹´åŒ–æ”¶ç›Šç‡ (252ä¸ªäº¤æ˜“æ—¥)
                annual_vol = daily_vol * np.sqrt(252)   # å¹´åŒ–æ³¢åŠ¨ç‡

                # è®¡ç®—å¤æ™®æ¯”ç‡: (å¹´åŒ–æ”¶ç›Š - æ— é£é™©åˆ©ç‡) / å¹´åŒ–æ³¢åŠ¨ç‡
                # å¤æ™®æ¯”ç‡è¡¡é‡æ¯å•ä½é£é™©è·å¾—çš„è¶…é¢æ”¶ç›Š
                sharpe_ratio = (annual_return - self.risk_free_rate) / annual_vol if (
                        annual_vol > 0) else -10
                # å­˜å‚¨æ€§èƒ½æŒ‡æ ‡
                performance_stats[ticker] = {
                    'annual_return': annual_return,
                    'annual_vol': annual_vol,
                    'sharpe_ratio': sharpe_ratio,
                    'trading_days': len(returns)
                }
                filtered_stocks[ticker] = df # å­˜å‚¨é€šè¿‡åˆæ­¥ç­›é€‰çš„è‚¡ç¥¨
            except Exception as e:
                print(f" åˆ†æ{ticker}å¤±è´¥: {e}")

        # æŒ‰å¤æ™®æ¯”ç‡ä»é«˜åˆ°åº•æ’åº, é€‰æ‹©è¡¨ç°æœ€å¥½çš„è‚¡ç¥¨
        # sortedå‡½æ•°: å¯¹performance_statså­—å…¸æŒ‰å¤æ™®æ¯”ç‡é™åºæ’åˆ—
        sorted_stocks = sorted(performance_stats.items(),
                               key=lambda x: x[1]['sharpe_ratio'],
                               reverse=True)
        selected_stocks = {}    # æœ€ç»ˆé€‰æ‹©çš„è‚¡ç¥¨
        selected_count = min(self.max_stocks, len(sorted_stocks))   # å®é™…é€‰æ‹©æ•°é‡
        print(f" \n é€‰æ‹©å‰{selected_count}åªè¡¨ç°æœ€å¥½çš„è‚¡ç¥¨:")

        # éå†æ’åºåçš„è‚¡ç¥¨, é€‰æ‹©å‰selected_countåª
        for i, (ticker, stats) in enumerate(sorted_stocks[:selected_count]):
            selected_stocks[ticker] = stock_data[ticker]    # ä»åŸå§‹æ•°æ®è·å–å®Œæ•´æ•°æ®
            # æ ¼å¼åŒ–è¾“å‡ºè‚¡ç¥¨ä¿¡æ¯
            print(f"{i+1:2d}. {ticker}: å¤æ™®{stats['sharpe_ratio']:+.2f},"
                  f"å¹´åŒ–{stats['annual_return']:.2%}, æ³¢åŠ¨{stats['annual_vol']:.2%}")
        return selected_stocks

    def calculate_returns(self, stock_data):
        '''
        è®¡ç®—æ‰€æœ‰è‚¡ç¥¨çš„æ”¶ç›Šç‡æ•°æ®
        åŠŸèƒ½: å°†ä»·æ ¼æ•°æ®è½¬ä¸ºæ”¶ç›Šç‡æ•°æ®, ä¸ºä¼˜åŒ–åšå‡†å¤‡
        å‚æ•°: ç­›é€‰åçš„è‚¡ç¥¨æ•°æ®
        è¿”å›: åŒ…å«æ‰€æœ‰è‚¡ç¥¨æ”¶ç›Šç‡çš„DataFrame
        '''
        print(f"\n è®¡ç®—è‚¡ç¥¨æ”¶ç›Šç‡........")
        returns_data = {}   # å­˜å‚¨æ¯åªè‚¡ç¥¨çš„æ”¶ç›Šç‡åºåˆ—

        for ticker, df in stock_data.items():
            try:
                # è®¡ç®—æ—¥æ”¶ç›Šç‡: (ä»Šæ—¥æ”¶ç›˜ä»· - æ˜¨æ—¥æ”¶ç›˜ä»·) / æ˜¨æ—¥æ”¶ç›˜ä»·
                returns = df['Close'].pct_change().dropna()
                returns_data[ticker] = returns    # å­˜å‚¨åˆ°å­—å…¸
                # è®¡ç®—æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
                daily_return = returns.mean()
                daily_vol = returns.std()
                annual_return = daily_return * 252
                annual_vol = daily_vol * np.sqrt(252)
                sharpe_ratio = (annual_return - self.risk_free_rate) / annual_vol

                # è¾“å‡ºæ¯åªè‚¡ç¥¨çš„è®¡ç®—æ•°æ®
                print(f" {ticker}: å¤æ™®{sharpe_ratio:+.2%}, å¹´åŒ–{annual_return:+.2%}, æ³¢åŠ¨{annual_vol:.2%}")
            except Exception as e:
                print(f" è®¡ç®—{ticker} æ”¶ç›Šç‡å¤±è´¥: {e}")

        # å°†æ”¶ç›Šç‡å­—å…¸è½¬ä¸ºDataFrame, å¹¶åˆ é™¤åŒ…å«NaNçš„è¡Œ
        returns_df = pd.DataFrame(returns_data).dropna()
        print(f" \n æœ€ç»ˆæ”¶ç›Šç‡æ•°æ®æ¡†å½¢çŠ¶: {returns_df.shape}")
        return returns_df

    def portfolio_optimization(self, returns_df, method='sharpe'):
        '''
        æŠ•èµ„ç»„åˆä¼˜åŒ–æ ¸å¿ƒå‡½æ•°
        åŠŸèƒ½: ä½¿ç”¨æ•°å­¦ä¼˜åŒ–æ–¹æ³•æ‰¾åˆ°æœ€ä¼˜çš„æƒé‡åˆ†é…
        å‚æ•°: returns_df: æ”¶ç›Šç‡æ•°æ®
            method: ä¼˜åŒ–æ–¹æ³• 'sharpe' = æœ€å¤§å¤æ™®æ¯”ç‡, 'min_variance'=æœ€å°æ–¹å·®
        è¿”å›: æœ€ä¼˜æƒé‡å­—å…¸å’Œç»„åˆè¡¨ç°
        '''
        print(f"\n è¿›è¡ŒæŠ•èµ„ç»„åˆä¼˜åŒ– - {method}...")
        # è®¡ç®—å¹´åŒ–ç»Ÿè®¡é‡
        expected_returns = returns_df.mean() * 252  # å¹´åŒ–æœŸæœ›æ”¶ç›Š
        cov_matrix = returns_df.cov() * 252         # å¹´åŒ–åæ–¹å·®çŸ©é˜µ

        n_assets = len(expected_returns)    # èµ„äº§æ•°é‡
        print(f" ä¼˜åŒ–èµ„äº§æ•°é‡: {n_assets}")

        # è®¾ç½®ä¼˜åŒ–çº¦æŸæ¡ä»¶: æƒé‡ä¹‹å’Œå¿…é¡»ç­‰äº1 (100%)
        constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})
        # è®¾ç½®è¾¹ç•Œæ¡ä»¶: æ¯ä¸ªæƒé‡åœ¨ 0 åˆ° 1 ä¹‹é—´ ( ä¸å…è®¸å–ç©º)
        bounds = tuple((0,1) for _ in range(n_assets))

        # åˆå§‹çŒœæµ‹: ç­‰æƒé‡åˆ†é…
        initial_weights = n_assets * [1.0 / n_assets]
        # æ ¹æ®ä¼˜åŒ–æ–¹æ³•é€‰æ‹©ç›®æ ‡å‡½æ•°
        if method == 'sharpe':
            # æœ€å¤§åŒ–å¤æ™®æ¯”ç‡ = æœ€å°åŒ–è´Ÿå¤æ™®æ¯”ç‡
            objective = lambda w: -self._calculate_sharpe(w, expected_returns, cov_matrix)
        else:
            # æœ€å°åŒ–æ³¢åŠ¨ç‡ ( æ–¹å·®)
            objective = lambda w: self._calculate_sharpe(w, cov_matrix)

        # ä½¿ç”¨SLSQPç®—æ³•è¿›è¡Œåºåˆ—æœ€å°äºŒä¹˜è§„åˆ’ä¼˜åŒ–
        result = sco.minimize(objective, initial_weights,
                              method='SLSQP', bounds=bounds, constraints=constraints)

        # æ£€æŸ¥ä¼˜åŒ–æ˜¯å¦æˆåŠŸ
        if result.success:
            optimal_weights = result.x  # æœ€ä¼˜æƒé‡å‘é‡
            portfolio_return = np.sum(optimal_weights * expected_returns)   # ç»„åˆæœŸæœ›æ”¶ç›Š
            portfolio_vol = self._calculate_volatility(optimal_weights, cov_matrix) # ç»„åˆæ³¢åŠ¨ç‡
            sharpe_ratio = self._calculate_sharpe(optimal_weights, expected_returns, cov_matrix)    # å¤æ™®æ¯”ç‡
            # å°†æƒé‡å‘é‡è½¬ä¸ºå­—å…¸æ ¼å¼ ( è‚¡ç¥¨ä»£ç : æƒé‡)
            weights_dict = dict(zip(returns_df.columns, optimal_weights))
            print(f" ä¼˜åŒ–æˆåŠŸ")
            return weights_dict, (portfolio_return, portfolio_vol, sharpe_ratio)
        else:
            print(f" ä¼˜åŒ–å¤±è´¥: {result.message}")
            # ä¼˜åŒ–å¤±è´¥æ—¶ä½¿ç”¨ç­‰æƒé‡ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
            return self._equal_weight_fallback(returns_df, expected_returns, cov_matrix)

    def _calculate_sharpe(self, weights, expected_returns, cov_matrix):
        '''
        è®¡ç®—å¤æ™®æ¯”ç‡çš„è¾…åŠ©å‡½æ•°
        å…¬å¼: å¤æ™®æ¯”ç‡ = (ç»„åˆæ”¶ç›Š - æ— é£é™©åˆ©ç‡) / ç»„åˆæ³¢åŠ¨ç‡
        '''
        port_return = np.sum(weights * expected_returns)    # ç»„åˆæœŸæœ›æ”¶ç›Š
        port_vol = self._calculate_volatility(weights, cov_matrix)  # ç»„åˆæ³¢åŠ¨ç‡
        if port_vol == 0:
            return 0        # é¿å…é™¤é›¶é”™è¯¯
        return (port_return - self.risk_free_rate) / port_vol

    def _calculate_volatility(self, weights, cov_matrix):
        '''
        è®¡ç®—ç»„åˆæ³¢åŠ¨ç‡çš„è¾…åŠ©å‡½æ•°
        å…¬å¼: æ³¢åŠ¨ç‡ = sqrt(æƒé‡^T * åæ–¹å·®çŸ©é˜µ * æƒé‡)
        '''
        return np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))

    def _equal_weight_fallback(self, returns_df, expected_returns, cov_matrix):
        '''
        ç­‰æƒé‡å¤‡é€‰æ–¹æ¡ˆ
        å½“ä¼˜åŒ–å¤±è´¥æ—¶ä½¿ç”¨ç®€å•çš„ç­‰æƒé‡åˆ†é…
        '''
        print(f" ä½¿ç”¨ç­‰æƒé‡ç»„åˆ")
        n_assets = len(returns_df.columns)
        equal_weights = np.array([1/n_assets] * n_assets)   # ç­‰æƒé‡å‘é‡

        #è®¡ç®—ç­‰æƒé‡ç»„åˆçš„è¡¨ç°
        port_return = np.sum(equal_weights * expected_returns)
        port_vol = self._calculate_volatility(equal_weights, cov_matrix)
        sharpe_ratio = self._calculate_sharpe(equal_weights, expected_returns, cov_matrix)

        weights_dict = dict(zip(returns_df.columns, equal_weights))
        return weights_dict, (port_return, port_vol, sharpe_ratio)

    def filter_significant_weights(self, weights, min_weight=0.01):
        '''
        è¿‡æ»¤æƒé‡å¤ªå°çš„è‚¡ç¥¨
        åŠŸèƒ½: ç®€åŒ–ä¼˜åŒ–æ˜¾ç¤º, åªä¿ç•™é‡è¦çš„æƒé‡åˆ†é…
        å‚æ•°: weights: åŸå§‹æƒé‡å­—å…¸
            min_weight: æœ€å°æƒé‡å€¼ (1%)
        è¿”å›: è¿‡æ»¤å¹¶é‡æ–°å½’ä¸€åŒ–åçš„æƒé‡
        '''
        # åªä¿ç•™æƒé‡å¤§äºç­‰äºåªçš„è‚¡ç¥¨
        significant_weights = {k: v for k, v in weights.items() if v >= min_weight}

        if significant_weights:
            # é‡æ–°å½’ä¸€åŒ–æƒé‡, ä½¿å…¶æ€»å’Œä¸º1
            total = sum(significant_weights.values())
            normalized_weights = {k: v/total for k, v in significant_weights.items()}
            print(f"\nç­›é€‰åä¿ç•™{len(normalized_weights)} åªé‡è¦è‚¡ç¥¨(æƒé‡>={min_weight:.1%})")
            return normalized_weights
        else:
            print(f"æ‰€æœ‰è‚¡ç¥¨æƒé‡éƒ½å¤ªå°, è¿”å›åŸå§‹æƒé‡")
            return weights

    def efficient_frontier_analysis(self, returns_df):
        """
        æœ‰æ•ˆå‰æ²¿åˆ†æ
        åŠŸèƒ½ï¼šé€šè¿‡è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿç”Ÿæˆæœ‰æ•ˆå‰æ²¿ï¼Œå±•ç¤ºé£é™©æ”¶ç›Šæƒè¡¡
        æœ‰æ•ˆå‰æ²¿ï¼šåœ¨ç»™å®šé£é™©æ°´å¹³ä¸‹èƒ½è·å¾—çš„æœ€å¤§æ”¶ç›Šè¾¹ç•Œ
        """
        print("\n ç”Ÿæˆæœ‰æ•ˆå‰æ²¿...")

        expected_returns = returns_df.mean() * 252
        cov_matrix = returns_df.cov() * 252
        n_assets = len(expected_returns)

        n_portfolios = 5000 # æ¨¡æ‹Ÿçš„æŠ•èµ„ç»„åˆæ•°é‡
        results = np.zeros((3, n_portfolios))   # å­˜å‚¨ç»“æœ: æ”¶ç›Š, é£é™©, å¤æ™®æ¯”ç‡

        # è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿï¼šéšæœºç”Ÿæˆæƒé‡ï¼Œè®¡ç®—ç»„åˆè¡¨ç°
        for i in range(n_portfolios):
            # ç”Ÿæˆéšæœºæƒé‡
            weights = np.random.random(n_assets)
            weights /= weights.sum()    # å½’ä¸€åŒ–æƒé‡
            # è®¡ç®—ç»„åˆè¡¨ç°
            port_return = np.sum(weights * expected_returns)
            port_vol = self._calculate_volatility(weights, cov_matrix)
            sharpe_ratio = self._calculate_sharpe(weights, expected_returns, cov_matrix)
            # å­˜å‚¨ç»“æœ
            results[0, i] = port_return # æ”¶ç›Š
            results[1, i] = port_vol    # é£é™©
            results[2, i] = sharpe_ratio    # å¤æ™®æ¯”ç‡
        return results

    def plot_optimization_results(self, returns_df, weights, performance, efficient_frontier=None):
        """
        ç»˜åˆ¶ä¼˜åŒ–ç»“æœå›¾è¡¨
        åŠŸèƒ½ï¼šé€šè¿‡4ä¸ªå­å›¾å…¨é¢å±•ç¤ºä¼˜åŒ–ç»“æœ
        å‚æ•°ï¼š
            returns_df: æ”¶ç›Šç‡æ•°æ®
            weights: æœ€ä¼˜æƒé‡
            performance: ç»„åˆè¡¨ç°ï¼ˆæ”¶ç›Šã€é£é™©ã€å¤æ™®ï¼‰
            efficient_frontier: æœ‰æ•ˆå‰æ²¿æ•°æ®
        """
        expected_return, volatility, sharpe_ratio = performance

        # åªæ˜¾ç¤ºæƒé‡ > 0 çš„è‚¡ç¥¨, ç®€åŒ–å›¾è¡¨
        non_zero_weights = {k: v for k, v in weights.items() if v > 0.001}
        # åˆ›å»º 2 X 2 çš„å­å›¾å¸ƒå±€
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('æŠ•èµ„ç»„åˆä¼˜åŒ–åˆ†æç»“æœ', fontsize=12, fontweight='bold')

        # å­å›¾1, æƒé‡åˆ†é…æŸ±çŠ¶å›¾
        if non_zero_weights:
            stocks = list(non_zero_weights.keys())
            weight_values = [w * 100 for w in non_zero_weights.values()]    # è½¬æ¢ä¸ºç™¾åˆ†æ¯”

            # ä½¿ç”¨Set3 è‰²å½©, ä¸ºæ¯åªè‚¡ç¥¨åˆ†é…ä¸åŒé¢œè‰²
            colors = plt.cm.Set3(np.linspace(0, 1, len(stocks)))
            bars = ax1.bar(stocks, weight_values, color=colors, alpha=0.8)
            ax1.set_title('æŠ•èµ„ç»„åˆæƒé‡åˆ†é… (æƒé‡>0)', fontsize=12, fontweight='bold')
            ax1.set_ylabel('æƒé‡ (%)')
            ax1.tick_params(axis='x', rotation=45)
            ax1.grid(True, alpha=0.3)

            # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, value, in zip(bars, weight_values):
                ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                         f'{value:.1f}%', ha='center', va='bottom', fontsize=9)
        else:
            ax1.text(0.5,0.5, 'æ— æ˜¾æƒé‡åˆ†é…', ha='center', va='venter', transform=ax1.transAxes)
            ax1.set_title('æŠ•èµ„ç»„åˆæƒé‡åˆ†é…', fontsize=12, fontweight='bold')

        # å­å›¾2: æœ‰æ•ˆå‰æ²¿
        if efficient_frontier is not None:
            scatter = ax2.scatter(efficient_frontier[1]*100, efficient_frontier[0]*100,
                                  c=efficient_frontier[2], cmap='viridis', alpha=0.6, s=1)
            # æ ‡è®°æœ€ä¼˜ç»„åˆä½ç½®
            ax2.scatter(volatility*100, expected_return*100, color='red', s=200,
                        marker='*', edgecolors='black', label='æœ€ä¼˜ç»„åˆ')
            ax2.set_xlabel('æ³¢åŠ¨ç‡ (%)')
            ax2.set_ylabel('æœŸæœ›æ”¶ç›Š (%)')
            ax2.set_title('æœ‰æ•ˆå‰æ²¿', fontsize=12, fontweight='bold')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            plt.colorbar(scatter, ax=ax2, label='å¤æ™®æ¯”ç‡')

        # å­å›¾3: ç´¯ç§¯æ”¶ç›Šç‡å¯¹æ¯”å›¾
        # åªæ˜¾ç¤ºæƒé‡è¾ƒå¤§çš„è‚¡ç¥¨, é¿å…å›¾è¡¨è¿‡äºæ‹¥æŒ¤
        significant_stocks = [k for k, v in weights.items() if v >= 0.01]
        if not significant_stocks:
            significant_stocks = list(weights.keys())[:6]   # å¦‚æœæ²¡ç”¨, æ˜¾ç¤ºå‰6åª
        # ç»˜åˆ¶æ¯åªé‡è¦è‚¡ç¥¨çš„ç´¯ç§¯æ”¶ç›Šç‡æ›²çº¿
        for ticker in significant_stocks:
            cumulative = (1 + returns_df[ticker]).cumprod() # è®¡ç®—ç´¯ç§¯æ”¶ç›Š
            ax3.plot(cumulative.index, cumulative, label=ticker, alpha=0.8, linewidth=2)
        # è®¡ç®—å¹¶ç»˜åˆ¶æŠ•èµ„ç»„åˆçš„ç´¯ç§¯æ”¶ç›Šç‡
        portfolio_returns = (returns_df * list(weights.values())).sum(axis=1)
        portfolio_cumulative = ( 1 + portfolio_returns).cumprod()
        ax3.plot(portfolio_cumulative.index, portfolio_cumulative,
                 label='æŠ•èµ„ç»„åˆ', linewidth=3, color='black', linestyle='--')
        ax3.set_title('ä¸»è¦è‚¡ç¥¨ç´¯ç§¯æ”¶ç›Šç‡å¯¹æ¯”', fontsize=12, fontweight='bold')
        ax3.set_ylabel('ç´¯ç§¯æ”¶ç›Š')
        ax3.legend()
        ax3.grid(True, alpha=0.3)

        # å­å›¾4: ç»„åˆè¡¨ç°æŒ‡æ ‡æŸ±çŠ¶å›¾
        metrics = ['æœŸæœ›æ”¶ç›Šç‡', 'æ³¢åŠ¨ç‡', 'å¤æ™®æ¯”ç‡']
        values = [expected_return*100, volatility*100, sharpe_ratio]
        colors = ['#2ecc71', '#e74c3c', '#3498db']
        bars = ax4.bar(metrics, values, color=colors, alpha=0.8)
        ax4.set_title('ç»„åˆè¡¨ç°æŒ‡æ ‡', fontsize=12, fontweight='bold')
        ax4.set_ylabel('ç™¾åˆ†æ¯”/æ¯”ç‡')
        ax4.grid(True, alpha=0.3)

        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value, metric in zip(bars, values, metrics):
            unit = '%' if metric != 'å¤æ™®æ¯”ç‡' else ''  # å¤æ™®æ¯”ç‡æ²¡ç”¨å•ä½
            ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() +0.1,
                     f"{value:.2f}{unit}", ha='center', va='bottom', fontweight='bold')

        # è°ƒæ•´å­å›¾è·ç¦»
        plt.tight_layout()
        plt.show()

    def risk_analysis(self, returns_df, weights):
        print(f"\n é£é™©åˆ†æ")
        # è®¡ç®—æŠ•èµ„ç»„åˆçš„æ—¥æ”¶ç›Šç‡
        portfolio_returns = (returns_df * list(weights.values())).sum(axis=1)

        # VaRè®¡ç®— (Value at Risk)
        # 95% VaR: æœ‰95% çš„æŠŠæ¡æŸå¤±ä¸ä¼šè¶…è¿‡è¿™ä¸ªå€¼
        var_95 = -np.percentile(portfolio_returns, 5) * 100
        # 99% VaR: æœ‰99% çš„æŠŠæ¡æŸå¤±ä¸ä¼šè¶…è¿‡è¿™ä¸ªå€¼
        var_99 = -np.percentile(portfolio_returns, 1) * 100

        # æœ€å¤§å›æ’¤è®¡ç®—
        cumulative = (1+ portfolio_returns).cumprod()   # ç´¯ç§¯æ”¶ç›Š
        running_max = cumulative.expanding().max()      # è¿è¡Œæœ€å¤§å€¼
        drawdown = (cumulative - running_max) / running_max # å›æ’¤æ¯”åˆ—
        max_drawdown = drawdown.min() * 100             # æœ€å¤§å›æ’¤

        print(f"æ—¥VaR (95%): {var_95:.2f}%")
        print(f"æ—¥VaR (99%): {var_99:.2f}%")
        print(f"æœ€å¤§å›æ’¤: {max_drawdown:.2f}%")

    def run_complete_analysis(self):
        """
        è¿è¡Œå®Œæ•´çš„æŠ•èµ„ç»„åˆåˆ†ææµç¨‹
        è¿™æ˜¯ä¸»è¦çš„æ‰§è¡Œå‡½æ•°ï¼ŒæŒ‰æ­¥éª¤è°ƒç”¨å„ä¸ªåŠŸèƒ½æ¨¡å—
        """
        print('=' * 70)
        print('æ™ºèƒ½æŠ•èµ„ç»„åˆä¼˜åŒ–åˆ†æ')
        print('=' * 70)

        #1. åŠ è½½æ‰€æœ‰æ•°æ®
        stock_data = self.load_all_stock_data()
        if not stock_data:
            return

        #2. ç­›é€‰ä¼˜è´¨è‚¡ç¥¨
        selected_stocks = self.filter_stocks_by_performance(stock_data)
        if not selected_stocks:
            print(f"æ²¡ç”¨ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
            return

        # 3. è®¡ç®—æ”¶ç›Šç‡
        returns_df = self.calculate_returns(selected_stocks)
        if returns_df.empty:
            return

        #4. æ‰§è¡ŒæŠ•èµ„ç»„åˆä¼˜åŒ–
        weights, performance = self.portfolio_optimization(returns_df, 'sharpe')
        if weights and performance:
            expected_return, volatility, sharpe_ratio=performance
            print(f"\n ä¼˜åŒ–ç»“æœ: ")
            print(f"é¢„æœŸå¹´åŒ–æ”¶ç›Šç‡: {expected_return:+.2%}")
            print(f"é¢„æœŸå¹´åŒ–æ³¢åŠ¨ç‡: {volatility:.2%}")
            print(f"å¤æ™®æ¯”ç‡: {sharpe_ratio:.2f}")

            # è¿‡æ»¤å°æƒé‡å›¾ç‰‡
            significant_weights = self.filter_significant_weights(weights)
            print(f"\n é‡è¦æƒé‡åˆ†é…")
            for stock, weight in significant_weights.items():
                print(f"{stock}: {weight:.2%}")

            # 5. é£é™©åˆ†æ
            self.risk_analysis(returns_df, weights)
            #6.
            efficient_frontier = self.efficient_frontier_analysis(returns_df)
            # 7. å¯è§†åŒ–
            self.plot_optimization_results(returns_df, weights, performance, efficient_frontier)
        print(f"\n åˆ†æå®Œæˆ")

# ç¨‹åºå…¥å£ç‚¹
if __name__ == '__main__':
    optimizer = SmartPortfolioOptimizer(max_stocks=15)
    optimizer.run_complete_analysis()


'''
æŠ•èµ„ç»„åˆä¼˜åŒ–é¡¹ç›®æ€»ç»“
ğŸ¯ é¡¹ç›®ç›®æ ‡å®Œæˆæƒ…å†µ
æˆåŠŸæ„å»ºäº†ä¸€ä¸ªå®Œæ•´çš„æ™ºèƒ½æŠ•èµ„ç»„åˆä¼˜åŒ–ç³»ç»Ÿï¼Œå®ç°äº†ä»æ•°æ®åŠ è½½ã€è‚¡ç¥¨ç­›é€‰ã€ç»„åˆä¼˜åŒ–åˆ°é£é™©åˆ†æå’Œå¯è§†åŒ–çš„å…¨æµç¨‹è‡ªåŠ¨åŒ–ã€‚

ğŸ“Š æ ¸å¿ƒæˆæœ
1. æ•°æ®ç®¡ç†
âœ… è‡ªåŠ¨æ‰«æåŠ è½½å¤šè‚¡ç¥¨å†å²æ•°æ®
âœ… æ•°æ®è´¨é‡éªŒè¯å’Œå®Œæ•´æ€§æ£€æŸ¥
âœ… æ”¯æŒ15åªè‚¡ç¥¨åŒæ—¶åˆ†æ

2. æ™ºèƒ½ç­›é€‰
âœ… åŸºäºå¤æ™®æ¯”ç‡çš„è‚¡ç¥¨æ’å
âœ… å¹´åŒ–æ”¶ç›Šç‡å’Œæ³¢åŠ¨ç‡è®¡ç®—
âœ… è‡ªåŠ¨é€‰æ‹©è¡¨ç°æœ€ä½³çš„è‚¡ç¥¨ç»„åˆ

3. ç»„åˆä¼˜åŒ–
âœ… æœ€å¤§å¤æ™®æ¯”ç‡ä¼˜åŒ–
âœ… æœ€å°æ–¹å·®ç»„åˆä¼˜åŒ–
âœ… æƒé‡çº¦æŸå¤„ç†ï¼ˆå’Œä¸º1ï¼Œç¦æ­¢å–ç©ºï¼‰

4. é£é™©åˆ†æ
âœ… VaRé£é™©ä»·å€¼è®¡ç®—ï¼ˆ95%/99%ï¼‰
âœ… æœ€å¤§å›æ’¤åˆ†æ
âœ… æ³¢åŠ¨ç‡ä¼°è®¡

5. å¯è§†åŒ–å±•ç¤º
âœ… å››åˆä¸€ä¸“ä¸šå›¾è¡¨
âœ… æƒé‡åˆ†é…æŸ±çŠ¶å›¾
âœ… æœ‰æ•ˆå‰æ²¿æ•£ç‚¹å›¾
âœ… ç´¯ç§¯æ”¶ç›Šæ›²çº¿å¯¹æ¯”
âœ… æ€§èƒ½æŒ‡æ ‡å±•ç¤º

ğŸ”§ æŠ€æœ¯å®ç°äº®ç‚¹
ç®—æ³•åº”ç”¨
SLSQPä¼˜åŒ–ç®—æ³• - å¤„ç†å¤æ‚çº¦æŸæ¡ä»¶
è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ - ç”Ÿæˆæœ‰æ•ˆå‰æ²¿
åæ–¹å·®çŸ©é˜µ - èµ„äº§ç›¸å…³æ€§å»ºæ¨¡

ä»£ç è´¨é‡
æ¨¡å—åŒ–è®¾è®¡ - åŠŸèƒ½ç‹¬ç«‹ï¼Œæ˜“äºç»´æŠ¤
å¼‚å¸¸å¤„ç† - å®Œå–„çš„é”™è¯¯å¤„ç†æœºåˆ¶
å‚æ•°å¯é…ç½® - çµæ´»è°ƒæ•´ä¼˜åŒ–å‚æ•°
'''